# 网络基础

## HTTP协议
###  TCP三次握手和四次分手

通俗理解：
![](https://camo.githubusercontent.com/91cee189ca7c400e3be6aa35cdda000ecbb58930/687474703a2f2f6f6f327239726e7a702e626b742e636c6f7564646e2e636f6d2f3630363537332d32303137303331373139313333363933322d313635343735313132332e706e67)

这个问题的本质是, 信道不可靠, 但是通信双发需要就某个问题达成一致. 而要解决这个问题, 无论你在消息中包含什么信息, 三次通信是理论上的最小值. 所以三次握手不是TCP本身的要求, 而是为了满足"在不可靠信道上可靠地传输信息"这一需求所导致的. 请注意这里的本质需求,信道不可靠, 数据传输要可靠. 三次达到了, 那后面你想接着握手也好, 发数据也好, 跟进行可靠信息传输的需求就没关系了. 因此,如果信道是可靠的, 即无论什么时候发出消息, 对方一定能收到, 或者你不关心是否要保证对方收到你的消息, 那就能像UDP那样直接发送消息就可以了.

### HTTP    请求建立
请求格式如下
![](https://static001.geekbang.org/resource/image/10/74/10ff27d1032bf32393195f23ef2f9874.jpg)
报文分为三个部分，请求行，首部，正文实体。

#### 第一部分：请求行

**方法** 

- GET:对于访问网页来讲，最常用的类型就是GET。顾名思义，GET 就是去服务器获取一些资源。对于访问网页来讲，要获取的资源往往是一个页面。其实也有很多其他的格式，比如说返回一个 JSON 字符串，到底要返回什么，是由服务器端的实现决定的。例如，在云计算中，如果我们的服务器端要提供一个基于 HTTP 协议的 API，获取所有云主机的列表，这就会使用 GET 方法得到，返回的可能是一个 JSON 字符串。字符串里面是一个列表，列表里面是一项的云主机的信息。
- 另外一种类型叫做POST。它需要主动告诉服务端一些信息，而非获取。要告诉服务端什么呢？一般会放在正文里面。正文可以有各种各样的格式。常见的格式也是 JSON。例如，我们下一节要讲的支付场景，客户端就需要把“我是谁？我要支付多少？我要买啥？”告诉服务器，这就需要通过 POST 方法。再如，在云计算里，如果我们的服务器端，要提供一个基于 HTTP 协议的创建云主机的 API，也会用到 POST 方法。这个时候往往需要将“我要创建多大的云主机？多少 CPU 多少内存？多大硬盘？”这些信息放在 JSON 字符串里面，通过 POST 的方法告诉服务器端。
- 还有一种类型叫PUT，就是向指定资源位置上传最新内容。但是，HTTP 的服务器往往是不允许上传文件的，所以 PUT 和 POST 就都变成了要传给服务器东西的方法。在实际使用过程中，这两者还会有稍许的区别。POST 往往是用来创建一个资源的，而 PUT 往往是用来修改一个资源的。例如，云主机已经创建好了，我想对这个云主机打一个标签，说明这个云主机是生产环境的，另外一个云主机是测试环境的。那怎么修改这个标签呢？往往就是用 PUT 方法。
- 再有一种常见的就是DELETE。这个顾名思义就是用来删除资源的。例如，我们要删除一个云主机，就会调用 DELETE 方法。

####   第二部分：首部字段

- Accept-Charset 表示客户端可以接受的字符集，防止外来传来的是宁外的字符集导致出现乱码。
- Content-Type是正文格式，在进行post请求时，如果正文是JSON，那个这个值就应该设为JSON。
- Cache-control用来控制缓存的，当客户端发送的请求中包含 max-age 指令时，如果判定缓存层中，资源的缓存时间数值比指定时间的数值小，那么客户端可以接受缓存的资源；当指定 max-age 值为 0，那么缓存层通常需要将请求转发给应用集群。
- If-Modified-Since也是关于缓存的，如果服务器的资源在摸个时间之后更新，client就应该下载最新资源。

比较重要的就是**缓存**例如，我浏览一个商品的详情，里面有这个商品的价格、库存、展示图片、使用手册等等。商品的展示图片会保持较长时间不变，而库存会根据用户购买的情况经常改变。如果图片非常大，而库存数非常小，如果我们每次要更新数据的时候都要刷新整个页面，对于服务器的压力就会很大。对于这种高并发场景下的系统，在真正的业务逻辑之前，都需要有个接入层，将这些静态资源的请求拦在最外面。

这个架构的图就像这样。
![](https://static001.geekbang.org/resource/image/c8/ac/c81af7a52305f7de27e32e34a02d0eac.jpg)


### HTTP请求的发送
就是报的发送过程

### HTTP2.0
当客户端发送的请求中包含 max-age 指令时，如果判定缓存层中，资源的缓存时间数值比指定时间的数值小，那么客户端可以接受缓存的资源；当指定 max-age 值为 0，那么缓存层通常需要将请求转发给应用集群。

HTTP 1.1 在应用层以纯文本的形式进行通信。每次通信都要带完整的 HTTP 的头，而且不考虑 pipeline 模式的话，每次的过程总是像上面描述的那样一去一回。这样在实时性、并发性上都存在问题。

为了解决这些问题，HTTP 2.0 会对 HTTP 的头进行一定的压缩，将原来每次都要携带的大量 key value 在两端建立一个索引表，对相同的头只发送索引表中的索引。

另外，HTTP 2.0 协议将一个 TCP 的连接中，切分成多个流，每个流都有自己的 ID，而且流可以是客户端发往服务端，也可以是服务端发往客户端。它其实只是一个虚拟的通道。流是有优先级的。

HTTP 2.0 还将所有的传输信息分割为更小的消息和帧，并对它们采用二进制格式编码。常见的帧有Header 帧，用于传输 Header 内容，并且会开启一个新的流。再就是Data 帧，用来传输正文实体。多个 Data 帧属于同一个流。

通过这两种机制，HTTP 2.0 的客户端可以将多个请求分到不同的流中，然后将请求内容拆成帧，进行二进制传输。这些帧可以打散乱序发送， 然后根据每个帧首部的流标识符重新组装，并且可以根据优先级，决定优先处理哪个流的数据。

![](https://static001.geekbang.org/resource/image/03/dd/03d4a216c024a9e761ed43c6787bf7dd.jpg)

HTTP2.0将三个请求变成三个流，将数据分成帧，乱序发送到一个TCP连接中。HTTP 2.0 成功解决了 HTTP 1.1 的队首阻塞问题，同时，也不需要通过 HTTP 1.x 的 pipeline 机制用多条 TCP 连接来实现并行请求与响应；减少了 TCP 连接数对服务器性能的影响，同时将页面的多个数据 css、js、 jpg 等通过一个数据链接进行传输，能够加快页面组件的传输速度。

### QUIC 协议

HTTP 2.0 虽然大大增加了并发性，但还是有问题的。因为 HTTP 2.0 也是基于 TCP 协议的，TCP 协议在处理包时是有严格顺序的。

当其中一个数据包遇到问题，TCP 连接需要等待这个包完成重传之后才能继续进行。虽然 HTTP 2.0 通过多个 stream，使得逻辑上一个 TCP 连接上的并行内容，进行多路数据的传输，然而这中间并没有关联的数据。一前一后，前面 stream 2 的帧没有收到，后面 stream 1 的帧也会因此阻塞。
google的QUIC协议基于UDP协议，解决了上述问题。

#### 机制一：自定义连接机制

不同于TCP中的连接用四元组标识， QUIC有自己的维护连接的机制，以64为的随机数作为ID来表示。

#### 机制二：自定义重传机制

HTTP 2.0 虽然大大增加了并发性，但还是有问题的。因为 HTTP 2.0 也是基于 TCP 协议的，TCP 协议在处理包时是有严格顺序的。

当其中一个数据包遇到问题，TCP 连接需要等待这个包完成重传之后才能继续进行。虽然 HTTP 2.0 通过多个 stream，使得逻辑上一个 TCP 连接上的并行内容，进行多路数据的传输，然而这中间并没有关联的数据。一前一后，前面 stream 2 的帧没有收到，后面 stream 1 的帧也会因此阻塞。

![](https://static001.geekbang.org/resource/image/da/c4/da2af1e419db66929dc85107c7250fc4.jpg)

#### 机制三：无阻塞的多路复用

#### 机制四：自定义流量控制


在 TCP 协议中，接收端的窗口的起始点是下一个要接收并且 ACK 的包，即便后来的包都到了，放在缓存里面，窗口也不能右移，因为 TCP 的 ACK 机制是基于序列号的累计应答，一旦 ACK 了一个系列号，就说明前面的都到了，所以只要前面的没到，后面的到了也不能 ACK，就会导致后面的到了，也有可能超时重传，浪费带宽。

QUIC 的 ACK 是基于 offset 的，每个 offset 的包来了，进了缓存，就可以应答，应答后就不会重发，中间的空挡会等待到来或者重发即可，而窗口的起始位置为当前收到的最大 offset，从这个 offset 到当前的 stream 所能容纳的最大缓存，是真正的窗口大小。显然，这样更加准确。

![](https://static001.geekbang.org/resource/image/a6/22/a66563b46906e7708cc69a02d43afb22.jpg)


## HTTPS协议

### 加密
加密分为二种，对称加密和非对称加密。
#### 对称加密
加密和解密使用的密钥是相同的，使用同一个密钥，这种要保证安全性的话，密钥要做好保密不能公开

#### 非对称加密

非对称加密算法中，加密使用的密钥和解密使用的密钥是不相同的。一把是作为公开的公钥，另一把是作为谁都不能给的私钥。公钥加密的信息，只有私钥才能解密。私钥加密的信息，只有公钥才能解密。

在订外卖的过程中，客户向网站发送数据时，客户使用外卖网站提供的公钥加密数据，网站使用对应的私钥解密。网站向客户端发送消息时，使用客户端的公钥。这样可以防止黑客攻击。

### 数字证书

如何将不对称加密的公钥发送给对放，一种是放在公网地址上，二个建立连接的时候，传给对方。

但是作为一个普通人，如何鉴定别人给你的公钥是对的。因为每个人都可以创建自己的公钥和私钥。这个时候就需要权威部门的介入了，就像每个人都可以打印自己的简历，说自己是谁，但是有公安局盖章的，就只有户口本，这个才能证明你是你。这个由权威部门颁发的称为证书。

证书里面有什么呢？当然应该有公钥，这是最重要的；还有证书的所有者，就像户口本上有你的姓名和身份证号，说明这个户口本是你的；另外还有证书的发布机构和证书的有效期，这个有点像身份证上的机构是哪个区公安局，有效期到多少年。

这个证书是怎么生成的呢？会不会有人假冒权威机构颁发证书呢？就像有假身份证、假户口本一样。生成证书需要发起一个证书请求，然后将这个请求发给一个权威机构去认证，这个权威机构我们称为CA（ Certificate Authority）。


将这个请求发给权威机构，权威机构会给这个证书卡一个章，我们称为 ** 签名算法。** 问题又来了，那怎么签名才能保证是真的权威机构签名的呢？当然只有用只掌握在权威机构手里的东西签名了才行，这就是 CA 的私钥。

签名算法大概是这样工作的：一般是对信息做一个 Hash 计算，得到一个 Hash 值，这个过程是不可逆的，也就是说无法通过 Hash 值得出原来的信息内容。在把信息发送出去时，把这个 Hash 值加密后，作为一个签名和信息一起发出去。

CA 用自己的私钥给外卖网站的公钥签名，就相当于给外卖网站背书，形成了外卖网站的证书。

通过层层授信背书的方式，保证了非对称加密模式的正常运转。

### HTTPS工作模式

将对称和非对称的加密结合起来。公钥私钥主要用于传输对称加密的秘钥，而真正的双方大数据量的通信都是通过对称加密进行的。
![](https://static001.geekbang.org/resource/image/70/02/7042f5c3d9e3437d5b0b30b30f43c802.jpg)

### 小结

- 对称加密效率高，但是解决不了密钥传输问题；非对称加密可以解决这个问题，但是效率不高
- 非对称加密需要通过证书和权威机构来验证公钥的合法性
- HTTPS综合了对称和非对称加密算法的HTTP协议

## 流媒体协议


### 视频和图片压缩过程的特点

- 空间冗余
- 时间冗余
- 视觉冗余
- 编码冗余

编码的过程如下

![](https://static001.geekbang.org/resource/image/43/b4/433a51e15d0ed50e313454ceccd61cb4.jpg)


### 视频编码的二个流派

- ITU International Telecommunications Union）的 VCEG（Video Coding Experts Group），这个称为国际电联下的 VCEG。既然是电信，可想而知，他们最初做视频编码，主要侧重传输。名词系列二，就是这个组织制定的标准。
- ISO（International Standards Organization）的 MPEG（Moving Picture Experts Group），这个是ISO 旗下的 MPEG，本来是做视频存储的。例如，编码后保存在 VCD 和 DVD 中。当然后来也慢慢侧重视频传输了。名词系列三，就是这个组织制定的标准。

主播直播到用户客户端的过程:

![](https://static001.geekbang.org/resource/image/e4/f8/e4d4b538c434ec0eade37028a34391f8.jpg)

### 编码：如何将图片变成二进制流

一个视频帧可以分成如下结构

![](https://static001.geekbang.org/resource/image/b8/70/b8f215697ce950005a532d3be341f570.jpg)

在一帧中，分成多个片，每个片中分成多个宏块，每个宏块分成多个子块，这样将一张大的图分解成一个个小块，可以方便进行空间上的编码。

尽管时空非常立体的组成了一个序列，但是总归还是要压缩成一个二进制流。这个流是有结构的，是一个个的网络提取层单元（NALU，Network Abstraction Layer Unit）。变成这种格式就是为了传输，因为网络上的传输，默认的是一个个的包，因而这里也就分成了一个个的单元。

![](https://static001.geekbang.org/resource/image/42/60/42dcd0705e3b1bad05d59fd9d6707d60.jpg)

一个视频，可以拆分成一系列的帧，每一帧拆分成一系列的片，每一片都放在一个 NALU 里面，NALU 之间都是通过特殊的起始标识符分隔，在每一个 I 帧的第一片前面，要插入单独保存 SPS 和 PPS 的 NALU，最终形成一个长长的 NALU 序列。

### RTMP 协议 --推流


## p2p协议

### FTP二种工作模式

#### 主动 PORT
主动模式下，客户端随机打开一个大于 1024 的端口 N，向服务器的命令端口 21 发起连接，同时开放 N+1 端口监听，并向服务器发出 “port N+1” 命令，由服务器从自己的数据端口 20，主动连接到客户端指定的数据端口 N+1。
#### 被动 PASV

被动模式下，当开启一个 FTP 连接时，客户端打开两个任意的本地端口 N（大于 1024）和 N+1。第一个端口连接服务器的 21 端口，提交 PASV 命令。然后，服务器会开启一个任意的端口 P（大于 1024），返回“227 entering passive mode”消息，里面有 FTP 服务器开放的用来进行数据传输的端口。客户端收到消息取得端口号之后，会通过 N+1 号端口连接服务器的端口 P，然后在两个端口之间进行数据传输。

### 种子文件

.torrent文件由二部分组成：announce（tracker URL）和文件信息。

文件信息包含这些内容：

- info区：该种子有几个文件，文件由多长，目录结构等
- Name字段：指定顶层目录名字
- 每个段的大小：BT协议把每个文件分成多个小段，然后分段下载
- 段哈希值：将整个种子中，每个段的SHA-1哈希值拼在一起

### 去中心化网络（DHT  ）

每个加入这个 DHT 网络的人，都要负责存储这个网络里的资源信息和其他成员的联系信息，相当于所有人一起构成了一个庞大的分布式存储数据库。

有一种著名的 DHT 协议，叫Kademlia 协议。任何一个 BitTorrent 启动之后，它都有两个角色。一个是peer，监听一个 TCP 端口，用来上传和下载文件，这个角色表明，我这里有某个文件。另一个角色DHT node，监听一个 UDP 的端口，通过这个角色，这个节点加入了一个 DHT 的网络。

![](https://static001.geekbang.org/resource/image/8e/cf/8ece62f3f99cb3fe7ee0274a1ad79fcf.jpg)


## DNS协议

有二项功能：

- 根据名称查到具体的地址
- 针对多个地址做负载均衡，在多个地址中选择一个距离你近的地方访问

## HTTPDNS 

### 传统DNS存在的问题

1. 域名缓存问题
    - 存在绕路问题，没有及时更新
2.  域名转发问题
    - 跨运营商访问
3. 出口NAT问题
    - 地址转换后，权威DNS服务器无法判断其来自哪个运营商
4. 域名更新问题
5. 解析延迟问题

### HTTPDNS 工作模式

HTTPNDS 其实就是，不走传统的 DNS 解析，而是自己搭建基于 HTTP 协议的 DNS 服务器集群，分布在多个地点和多个运营商。当客户端需要 DNS 解析的时候，直接通过 HTTP 协议进行请求这个服务器集群，得到就近的地址。

这就相当于每家基于 HTTP 协议，自己实现自己的域名解析，自己做一个自己的地址簿，而不使用统一的地址簿。但是默认的域名解析都是走 DNS 的，因而使用 HTTPDNS 需要绕过默认的 DNS 路径，就不能使用默认的客户端。使用 HTTPDNS 的，往往是手机应用，需要在手机端嵌入支持 HTTPDNS 的客户端 SDK。

![](https://static001.geekbang.org/resource/image/91/00/914d44e3d9246804b1b670b216146100.jpg)
 
 解析速度和更新速度的平衡问题；智能调度问题。对应的解决方案是HTTPDNS的缓存设计和调度设计
 
####  缓存设计

传统的DNS缓存信息都存放在本地DNS服务器中，不会为客户端定制。在HTTPDNS中，将解析速度和更新速度全部掌控在自己手中。一方面，解析的过程，不需要本地 DNS 服务递归的调用一大圈，一个 HTTP 的请求直接搞定，要实时更新的时候，马上就能起作用；另一方面为了提高解析速度，本地也有缓存，缓存是在客户端 SDK 维护的，过期时间、更新时间，都可以自己控制。

同步解析：直接调用HTTPDNS的接口，返回最新的记录更新缓存

异步解析：添加一个解析任务到后台，由后台任务调用HTTPDNS的接口

#### 调度设计

将解析速度和更新速度全部掌控在自己手中。一方面，解析的过程，不需要本地 DNS 服务递归的调用一大圈，一个 HTTP 的请求直接搞定，要实时更新的时候，马上就能起作用；另一方面为了提高解析速度，本地也有缓存，缓存是在客户端 SDK 维护的，过期时间、更新时间，都可以自己控制。

HTTPDNS服务器的地址一般不可变，可以使用dns的方式获取httpdns服务器的ip地址

## CDN

CDN的分发系统架构

![](https://static001.geekbang.org/resource/image/d8/cc/d8c77f59d6b7ac894b5192252239cfcc.jpg)

有了这个分发系统后，client如何找到相应的边缘节点进行访问。

- CDN和电商系统的分布式仓储系统一样，分为中心节点，区域节点，边缘节点，数据缓存在距离用户最近的位置
- CDN最擅长的是缓存静态数据，除此之外还可以缓存流媒体数据。它也支持动态数据的缓存，一种是边缘计算的生鲜超市模式，宁一种是链路优化的冷链运输模式。

##  数据中心

数据中心服务器放在机架上（Rack) 。

数据中心的架构 

![](https://static001.geekbang.org/resource/image/90/eb/9002b47ad5dc7762faf37e60250211eb.jpg)

南北流量:这里的三层不是指 IP 层，而是指接入层、汇聚层、核心层三层。这种模式非常有利于外部流量请求到内部应用。这个类型的流量，是从外到内或者从内到外，对应到上面那张图里，就是从上到下，从下到上，上北下南，所以称为南北流量。

东西流量:但是随着云计算和大数据的发展，节点之间的交互越来越多，例如大数据计算经常要在不同的节点将数据拷贝来拷贝去，这样需要经过交换机，使得数据从左到右，从右到左，左西右东，所以称为东西流量。

为了解决东西流量问题，出现了叶脊网络（Spine/Leaf）

- 叶子交换机（leaf），直接连接物理服务器。L2/L3 网络的分界点在叶子交换机上，叶子交换机之上是三层网络。
- 脊交换机（spine switch），相当于核心交换机。叶脊之间通过 ECMP 动态选择多条路径。脊交换机现在只是为叶子交换机提供一个弹性的 L3 路由网络。南北流量可以不用直接从脊交换机发出，而是通过与 leaf 交换机并行的交换机，再接到边界路由器出去。

![](https://static001.geekbang.org/resource/image/99/92/99f86d113a629d81bb52786d80ca5c92.jpg)

### 小结

- 数据中心分为三层。服务器连接到接入层，然后是汇聚层，再然后是核心层，最外面是边界路由器和安全设备。
- 数据中心的所有链路都需要高可用性。服务器需要绑定网卡，交换机需要堆叠，三层设备可以通过等价路由，二层设备可以通过 TRILL 协议。
- 着云和大数据的发展，东西流量相对于南北流量越来越重要，因而演化为叶脊网络结构。

## VPN

### vpn如何工作的

VPN 通过隧道技术在公众网络上仿真一条点到点的专线，是通过利用一种协议来传输另外一种协议的技术，这里面涉及三种协议：乘客协议、隧道协议和承载协议。

![](https://static001.geekbang.org/resource/image/a7/f1/a7c0a7fd2334d7145d093cf24bc6d7f1.jpg)

IPsecVPN,基于IP协议的安全隧道协议，采用了一定的机制保证安全性：

- 机制一：私密性
- 机制二：完整性
- 机制三：真实性

以上三个特征组成了IPsecVPN的协议族，这个簇中有二种协议，区别在于封装网络包的格式不一样。

- AH（Authentication Header），只能进行数据摘要 ，不能实现数据加密。
- ESP（Encapsulating Security Payload），能够进行数据加密和数据摘要。

![](https://static001.geekbang.org/resource/image/34/af/34a952bd1abeec19460b8d5dca5cd0af.jpg)

在这个协议簇里面，还有两类算法，分别是加密算法和摘要算法。

这个协议簇还包含两大组件，

- 一个用于 VPN 的双方要进行对称密钥的交换的IKE 组件，
- 另一个是 VPN 的双方要对连接进行维护的SA（Security Association）组件。

### IPsecVPN的建立过程

#### 建立IKE自己的SA 

具体过程如下
![](https://static001.geekbang.org/resource/image/28/78/28a3938ab8efaf9fa7f313a46d0e1478.jpg)

#### 建立IPsec SA


IPsec SA 里面有以下内容：

- SPI（Security Parameter Index），用于标识不同的连接；
- 双方商量好的加密算法、哈希算法和封装模式；
- 生存周期，超过这个周期，就需要重新生成一个 IPsec SA，重新生成对称密钥。

![](https://static001.geekbang.org/resource/image/87/59/87a34817f22ed4a2afb58e8f6496f159.jpg)

### 多协议标签交换
 
  在原始IP头之外，多了MPLS的头，里面可以打标签。
在二层头里面，有类型字段，0x0800 表示 IP，0x8847 表示 MPLS Label。

在 MPLS 头里面，首先是标签值占 20 位，接着是 3 位实验位，再接下来是 1 位栈底标志位，表示当前标签是否位于栈底了。这样就允许多个标签被编码到同一个数据包中，形成标签栈。最后是 8 位 TTL 存活时间字段，如果标签数据包的出发 TTL 值为 0，那么该数据包在网络中的生命期被认为已经过期了。

有了标签，还需要设备认这个标签，并且能够根据这个标签转发，这种能够转发标签的路由器称为标签交换路由器（LSR，Label Switching Router）。



 
 ![](https://static001.geekbang.org/resource/image/ab/32/ab77ad0cec6a26f43bacb3f51b0c8d32.jpg)


这种路由器会有两个表格，一个就是传统的 FIB，也即路由表，另一个就是 LFIB，标签转发表。有了这两个表，既可以进行普通的路由转发，也可以进行基于标签的转发。

![](https://static001.geekbang.org/resource/image/78/ee/782742e09ddddcef169c9982b65c69ee.jpg)


### MPLS VPN 


在 MPLS VPN 中，网络中的路由器分成以下几类：

- PE（Provider Edge）：运营商网络与客户网络相连的边缘网络设备；
- CE（Customer Edge）：客户网络与 PE 相连接的边缘设备；
- P（Provider）：这里特指运营商网络中除 PE 之外的其他运营商网络设备。

![](https://static001.geekbang.org/resource/image/ba/ec/bae67c4e3f4a4127bad07de4bb577bec.jpg)


## 软件定义网络

## 云中网络的QOS

在Linux下，可以通过TC控制网络的 QOS,主要就是通过队列的方式

###  无类别排队规则

**pfifo_fast**这是一种不把网络包分类的技术
![](https://static001.geekbang.org/resource/image/7e/3e/7e3218260e75bb9f18d68641928ff33e.jpg)

**随机公平队列**,会建立很多的 FIFO 的队列，TCP Session 会计算 hash 值，通过 hash 值分配到某个队列。在队列的另一端，网络包会通过轮询策略从各个队列中取出发送。这样不会有一个 Session 占据所有的流量。

当然如果两个 Session 的 hash 是一样的，会共享一个队列，也有可能互相影响。hash 函数会经常改变，从而 session 不会总是相互影响。
![](https://static001.geekbang.org/resource/image/da/71/da3a4653469877d9d98f1610ccaefd71.jpg)

**令牌桶规则**

网络包排成队列进行发送，不是到了队头就能发送，需要拿到令牌才能发送。
![](https://static001.geekbang.org/resource/image/c2/15/c2170423769b8dfb6e6ff854287ab115.jpg)


### 基于类别的排队规则

**分层令牌桶规则HTC**

![](https://static001.geekbang.org/resource/image/9a/b5/9a1b8a7c0c5403a2b4b3c277545991b5.jpg)

## RPC协议

对于服务之间的远程调用该如何实现？是否使用之前的socket就可以了。其实需要解决的问题有很多

- 问题一：如何规定远程调用的语法
- 问题二：如何传递参数
- 问题三：如何表示数据
- 问题四：如何知道一个服务端都实现了哪些远程调用？那个端口可以访问这个远程调用
- 问题五：发生了错误，重传，丢包，性能等问题怎么办

以上问题可以通过RPC协议解决 

![](https://static001.geekbang.org/resource/image/85/25/8534c52daf3682cd1cfe5a3375ec9525.jpg)

当客户端的应用想发起一个远程调用时，它实际是通过本地调用本地调用方的 Stub。它负责将调用的接口、方法和参数，通过约定的协议规范进行编码，并通过本地的 RPCRuntime 进行传输，将调用网络包发送到服务器。

服务器端的 RPCRuntime 收到请求后，交给提供方 Stub 进行解码，然后调用服务端的方法，服务端执行方法，返回结果，提供方 Stub 将返回结果编码后，发送给客户端，客户端的 RPCRuntime 收到结果，发给调用方 Stub 解码得到结果，返回给客户端。

这里面分了三个层次，对于用户层和服务端，都像是本地调用一样，专注于业务逻辑的处理就可以了。对于 Stub 层，处理双方约定好的语法、语义、封装、解封装。对于 RPCRuntime，主要处理高性能的传输，以及网络的错误和异常。
### 传输问题

错误、重传、丢包、性能等问题还没有解决，这些问题我们统称为传输问题。这个就不用 Stub 操心了，而是由 ONC RPC 的类库来实现

![](https://static001.geekbang.org/resource/image/02/f5/0258775aac1126735504c9a6399745f5.jpg)

首先，进入起始状态，查看 RPC 的传输层队列中有没有空闲的位置，可以处理新的 RPC 任务。如果没有，说明太忙了，或直接结束或重试。如果申请成功，就可以分配内存，获取服务的端口号，然后连接服务器。

连接的过程要有一段时间，因而要等待连接的结果，会有连接失败，或直接结束或重试。如果连接成功，则开始发送 RPC 请求，然后等待获取 RPC 结果，这个过程也需要一定的时间；如果发送出错，可以重新发送；如果连接断了，可以重新连接；如果超时，可以重新传输；如果获取到结果，就可以解码，正常结束。

这里处理了连接失败、重试、发送失败、超时、重试等场景。不是大牛真写不出来，因而实现一个 RPC 的框架，其实很有难度。

### 服务发现问题

如何找到RPC服务端的那个随机端口，这个被称为服务发现问题。在ONC RPC中服务发现是通过portmapper实现的。
![](https://static001.geekbang.org/resource/image/2a/7c/2aff190d1f878749d2a5bd73228ca37c.jpg)

portmapper 会启动在一个众所周知的端口上，RPC 程序由于是用户自己写的，会监听在一个随机端口上，但是 RPC 程序启动的时候，会向 portmapper 注册。客户端要访问 RPC 服务端这个程序的时候，首先查询 portmapper，获取 RPC 服务端程序的随机端口，然后向这个随机端口建立连接，开始 RPC 调用。从图中可以看出，mount 命令的 RPC 调用，就是这样实现的。

### 存在问题

- 需要双方的压缩格式完全一致，一点都不能差。一旦有少许的差错，多一位，少一位或者错一位，都可能造成无法解压缩。当然，我们可以用传输层的可靠性以及加入校验值等方式，来减少传输过程中的差错。
- 其次，协议修改不灵活。如果不是传输过程中造成的差错，而是客户端因为业务逻辑的改变，添加或者删除了字段，或者服务端添加或者删除了字段，而双方没有及时通知，或者线上系统没有及时升级，就会造成解压缩不成功。
- 版本问题

面向函数，而非面向对象的


## SOAP 

### ONC RPC存在的问题

- 需要双方的压缩格式完全一致
- 协议修改不灵活
- 当有很多设备时，版本同步的问题

### XML和SOAP

使用文本类的方式进行传输，无论哪个客户端获得这个文本都可以知道其意义。基于XML的最著名的通信协议就是SOAP，全称简单对象访问协议。它使用XML编写简单的请求和回复消息，并用HTTP协议进行传输。

### 协议约定问题

使用Web服务描述语言WSDL，这也是一个XML文件，在这个文件中要定义一个类型order，message结构，暴露一个接口，自己编写一个binding将上面定义的信息绑定到SOAP请求的body中。最后我们需要编写service。
### 服务发现
有一个UDDI 统一描述发现和集成协议。它其实是一个注册中心，服务提供方可以将上面的 WSDL 描述文件，发布到这个注册中心，注册完毕后，服务使用方可以查找到服务的描述，封装为本地的客户端进行调用。

## RSETful
面向资源，提供无状态服务，有利于横向扩展应对高并发

RESTful不仅仅是API，而是一种架构风格，全称为表述性状态转移，来自一篇论文《架构风格与基于网络的软件架构设计》

本地调用和远程跨网络调用的不一样，这里的不一样不仅仅是因为有网络导致的客户端和服务端的分离，从而带来的网络问题，更重要的是客户端和服务器状态的维护，所谓的状态就是对某个数据当前处理到什么程度了。

在RPC场景下，有服务端来维护状态，很多SOAP接口设计的时候，也常常按照这个模式。这种模式原来没有问题，是因为客户端和服务端之间的比例没有失衡。因为一般不会同时有太多的客户端同时连上来，所以 NFS 还能把每个客户端的状态都记住。

但是在双十一的场景下，不可能通过服务器去维护每一个用户的状态，当涉及到用户状态转移的时候，更加 的复杂。服务端和客户端数量的不匹配性，针对这样的问题 ，服务端只会记录资源的状态例如文件的状态报表的状态，而客户端自己维护自己的状态。

上述的就是服务端的无状态化，这样服务端就可以横向扩展，一百个人一起服务不用交接，每个人都能处理。

**所谓的无状态，其实是服务端维护资源的状态，客户端维护会话的状态。对于服务端来讲，只有资源的状态改变了，客户端才调用 POST、PUT、DELETE 方法来找我；如果资源的状态没变，只是客户端的状态变了，就不用告诉我了，对于我来说都是统一的 GET。**

对于库存调用来说，应该查看当前的库存数目，然后减去购买的数量，得到结果的库存数，这个时候应该设置为目标库存数，而非告知减去多少库存。

### 服务发现

服务分服务提供方，它向 Eureka 做服务注册、续约和下线等操作，注册的主要数据包括服务名、机器 IP、端口号、域名等等。

另外一方是服务消费方，向 Eureka 获取服务提供方的注册信息。为了实现负载均衡和容错，服务提供方可以注册多个。


当消费方要调用服务的时候，会从注册中心读出多个服务来，那怎么调用呢？当然是 RESTful 方式了。

Spring Cloud 提供一个 RestTemplate 工具，用于将请求对象转换为 JSON，并发起 Rest 调用，RestTemplate 的调用也是分 POST、PUT、GET、 DELETE 的，当结果返回的时候，根据返回的 JSON 解析成对象。


## 二进制类RPC协议

### 数据中心内部如何互相调用

API 网关用来管理 API，但是 API 的实现一般在一个叫作Controller 层的地方。这一层对外提供 API。由于是让陌生人访问的，我们能看到目前业界主流的，基本都是 RESTful 的 API，是面向大规模互联网应用的。

Controller 层、组合服务层、基础服务层就会相互调用，这个调用是在数据中心内部的，量也会比较大，还是使用 RPC 的机制实现的。由于服务比较多，需要有单独的注册中心来做服务发现，服务提供方会将自己提供哪些服务注册到注册中心去，同时服务消费方订阅这个服务，从而可以对这个服务进行调用。
![](https://static001.geekbang.org/resource/image/f0/b8/f08ef51889add2c26c57c9edd3db93b8.jpg)


 内部调用使用的RPC调用是二进制的，节省带宽时延小。
 
 Dubbo 服务化框架二进制的 RPC 方式。

 ![](https://static001.geekbang.org/resource/image/c6/c2/c622af64f47e264453088e79c3e631c2.jpg)

Dubbo 中默认的RPC协议时Hessian2，为了保证传输效率，其将远程调用序列化为二进制进行传输，并且进行了压缩。


### 小结

- RESTful API 对于接入层和 Controller 层之外的调用，已基本形成事实标准，但是随着内部服务之间的调用越来越多，性能也越来越重要，于是 Dubbo 的 RPC 框架有了用武之地。
- Dubbo 通过注册中心解决服务发现问题，通过 Hessian2 序列化解决协议约定的问题，通过 Netty 解决网络传输的问题。
- 在更加复杂的微服务场景下，Spring Cloud 的 RESTful 方式在内部调用也会被考虑，主要是 JAR 包的依赖和管理问题。

## 跨语言类RPC协议

RPC从最初的c/s模式演进到了微服务，对于PRC框架的要求越来越多:


- 首先，传输性能很重要。因为服务之间的调用如此频繁了，还是二进制的越快越好。
- 其次，跨语言很重要。因为服务多了，什么语言写成的都有，而且不同的场景适宜用不同的语言，不能一个语言走到底。
- 最好既严谨又灵活，添加个字段不用重新编译和发布程序。
- 最好既有服务发现，也有服务治理，就像 Dubbo 和 Spring Cloud 一样。

### GRPC



GRPC 首先满足二进制和跨语言这两条，二进制说明压缩效率高，跨语言说明更灵活。但是又是二进制，又是跨语言，这就相当于两个人沟通，你不但说方言，还说缩略语，人家怎么听懂呢？所以，最好双方弄一个协议约定文件，里面规定好双方沟通的专业术语，这样沟通就顺畅多了。对于GRPC来说，二进制序列化协议是Protocol Buffers


#### 协议约定问题
Protocol Buffers 是一款压缩效率极高的序列化协议，有很多设计精巧的序列化方法。
#### 网络传输问题
如果是 Java 技术栈，GRPC 的客户端和服务器之间通过 Netty Channel 作为数据通道，每个请求都被封装成 HTTP 2.0 的 Stream。
#### 服务发现与治理问题

  **Envoy**
  
  其不仅是一个负载均衡器还是一个Proxy转发器，可以配置非常灵活的转发规则。
这些规则可以是静态的，放在配置文件中的，在启动的时候加载。要想重新加载，一般需要重新启动，但是 Envoy 支持热加载和热重启，这在一定程度上缓解了这个问题。

当然，最好的方式是将规则设置为动态的，放在统一的地方维护。这个统一的地方在 Envoy 眼中被称为服务发现（Discovery Service），过一段时间去这里拿一下配置，就修改了转发策略。

无论是静态的，还是动态的，在配置里面往往会配置四个东西。

1.  listener。Envoy 既然是 Proxy，专门做转发，就得监听一个端口，接入请求，然后才能够根据策略转发，这个监听的端口就称为 listener。
2.  endpoint，是目标的 IP 地址和端口。这个是 Proxy 最终将请求转发到的地方。
3.  cluster。一个 cluster 是具有完全相同行为的多个 endpoint，也即如果有三个服务端在运行，就会有三个 IP 和端口，但是部署的是完全相同的三个服务，它们组成一个 cluster，从 cluster 到 endpoint 的过程称为负载均衡，可以轮询。
4.  route。有时候多个 cluster 具有类似的功能，但是是不同的版本号，可以通过 route 规则，选择将请求路由到某一个版本号，也即某一个 cluster。

动态的需要配置一个服务发现中心，这个服务中心要实现Envoy的API，Envoy可以主动去服务发现中心拉去转发策略。
![](https://static001.geekbang.org/resource/image/ef/ce/ef916f46dc293ac2d5739b496f0b27ce.jpg)


当配置策略变得很复杂是，可以有更大作用：

- 配置路由策略
- 负责均衡策略

![](https://static001.geekbang.org/resource/image/50/3c/50443d6848f890e475e71be11489d33c.jpg)

所有这些节点的变化都会上传到注册中心，所有这些策略都可以通过注册中心进行下发，所以，更严格的意义上讲，注册中心可以称为注册治理中心。如果我们的应用能够意识不到服务治理的存在，就是直接进行 GRPC 的调用就可以了。

这就是未来服务治理的趋势Service Mesh, 应用之间的相互调用全部有Envoy进行代理，服务之间的治理也被Envoy进行代理，完全将服务治理抽象出来，到平台层解决

![](https://static001.geekbang.org/resource/image/15/02/15e254a8e92e031b20feb6ebdcc32402.jpg)



## 网络协议串讲

![](https://static001.geekbang.org/resource/image/ed/20/eddde5929de2a72b197321e5ad87e120.jpg)