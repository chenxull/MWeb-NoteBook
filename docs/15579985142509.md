# harbor 之 Jobservice 解析 （二）

整理 api 入口对各种请求是如何处理的以及如何启动具体的任务。

## core
在`interface.go`中抽象了对` job`操作的主要方法，这些方法直接对应的` api `服务器接收到请求后所调用的处理函数。`job`的接口定义了如下的方法：

```go、
type Interface interface {
	// LaunchJob is used to handle the job submission request.
	//
	// req	JobRequest    : Job request contains related required information of queuing job.
	//
	// Returns:
	//	JobStats: Job status info with ID and self link returned if job is successfully launched.
	//  error   : Error returned if failed to launch the specified job.
	LaunchJob(req models.JobRequest) (models.JobStats, error)

	// GetJob is used to handle the job stats query request.
	//
	// jobID	string: ID of job.
	//
	// Returns:
	//	JobStats: Job status info if job exists.
	//  error   : Error returned if failed to get the specified job.
	GetJob(jobID string) (models.JobStats, error)

	// StopJob is used to handle the job stopping request.
	//
	// jobID	string: ID of job.
	//
	// Return:
	//  error   : Error returned if failed to stop the specified job.
	StopJob(jobID string) error

	// RetryJob is used to handle the job retrying request.
	//
	// jobID	string        : ID of job.
	//
	// Return:
	//  error   : Error returned if failed to retry the specified job.
	RetryJob(jobID string) error

	// Cancel the job
	//
	// jobID string : ID of the enqueued job
	//
	// Returns:
	//  error           : error returned if meet any problems
	CancelJob(jobID string) error

	// CheckStatus is used to handle the job service healthy status checking request.
	CheckStatus() (models.JobPoolStats, error)

	// GetJobLogData is used to return the log text data for the specified job if exists
	 GetJobLogData(jobID string) ([]byte, error)
}

```

上述接口抽象出来就构成了整个`jobservice`的` controller`，`controller`在实现上述方法的同时也在结构体中定了对后端` redis pool`接口的继承。通过这种方式` controller`完成了对底层操作` redis`的封装。结构体定义如下：

```go
type Controller struct {
	// Refer the backend pool
	// Controller 结构体继承了 pool的 interface，用来实现对 redis pool 的各种操作.
	backendPool pool.Interface
}
```

`redis pool`的接口定义如下：
```go
type Interface interface {
	// Start to serve
	//
	// Return:
	//  error if failed to start
	Start() error

	// Register job to the pool.
	//
	// name	string     : job name for referring
	// job	interface{}: job handler which must implement the job.Interface.
	//
	// Return:
	//  error if failed to register
	RegisterJob(name string, job interface{}) error

	// Register multiple jobs.
	//
	// jobs	map[string]interface{}: job map, key is job name and value is job handler.
	//
	// Return:
	//  error if failed to register
	RegisterJobs(jobs map[string]interface{}) error

	// Enqueue job
	//
	// jobName string           : the name of enqueuing job
	// params models.Parameters : parameters of enqueuing job
	// isUnique bool            : specify if duplicated job will be discarded
	//
	// Returns:
	//  models.JobStats: the stats of enqueuing job if succeed
	//  error          : if failed to enqueue
	Enqueue(jobName string, params models.Parameters, isUnique bool) (models.JobStats, error)

	// Schedule job to run after the specified interval (seconds).
	//
	// jobName string           : the name of enqueuing job
	// runAfterSeconds uint64   : the waiting interval with seconds
	// params models.Parameters : parameters of enqueuing job
	// isUnique bool            : specify if duplicated job will be discarded
	//
	// Returns:
	//  models.JobStats: the stats of enqueuing job if succeed
	//  error          : if failed to enqueue
	// 调度 job 的执行
	Schedule(jobName string, params models.Parameters, runAfterSeconds uint64, isUnique bool) (models.JobStats, error)

	// Schedule the job periodically running.
	//
	// jobName string           : the name of enqueuing job
	// params models.Parameters : parameters of enqueuing job
	// cronSetting string       : the periodic duration with cron style like '0 * * * * *'
	//
	// Returns:
	//  models.JobStats: the stats of enqueuing job if succeed
	//  error          : if failed to enqueue
	// 调度 job 周期性执行
	PeriodicallyEnqueue(jobName string, params models.Parameters, cronSetting string) (models.JobStats, error)

	// Return the status info of the pool.
	//
	// Returns:
	//  models.JobPoolStats : the stats info of all running pools
	//  error               :  failed to check
	// 获取 worker pool 的信息
	Stats() (models.JobPoolStats, error)

	// Check if the job has been already registered.
	//
	// name string : name of job
	//
	// Returns:
	// interface{} : the job type of the known job if it's existing
	// bool        : if the known job requires parameters
	// 检测 job 是否在 worker pool 中注册
	IsKnownJob(name string) (interface{}, bool)

	// Validate the parameters of the known job
	//
	// jobType interface{}            : type of known job
	// params map[string]interface{} : parameters of known job
	//
	// Return:
	//  error if parameters are not valid
	// 验证 job 的参数
	ValidateJobParameters(jobType interface{}, params map[string]interface{}) error

	// Get the stats of the specified job
	//
	// jobID string : ID of the enqueued job
	//
	// Returns:
	//  models.JobStats : job stats data
	//  error           : error returned if meet any problems
	GetJobStats(jobID string) (models.JobStats, error)

	// Stop the job
	//
	// jobID string : ID of the enqueued job
	//
	// Return:
	//  error           : error returned if meet any problems
	StopJob(jobID string) error

	// Cancel the job
	//
	// jobID string : ID of the enqueued job
	//
	// Return:
	//  error           : error returned if meet any problems
	CancelJob(jobID string) error

	// Retry the job
	//
	// jobID string : ID of the enqueued job
	//
	// Return:
	//  error           : error returned if meet any problems
	RetryJob(jobID string) error

	// Register hook
	//
	// jobID string   : ID of job
	// hookURL string : the hook url
	//
	// Return:
	//  error        : error returned if meet any problems
	RegisterHook(jobID string, hookURL string) error
}

```
实现这一接口的结构体为`GoCraftWorkPool`，也就是`controller`实际上同通过`GoCraftWorkPool`结构体的方法来对` redis pool`进行各种详细的操作。通过这二层接口的封装，大大提高的抽象性。
### 方法的具体实现

#### LaunchJob


- 首先会验证` req`的合理性也就是说只有符合要求的请求才会被处理
- 验证完合理性之后开始从` backendPool`中检查`req`中所表示的 `job name`是否注册在其中
- 验证完名字之后验证此` job`的类型和`req`中的参数是否相符合。通过接口反射的方式 ，根据 `jobType` 获取到了`job` 的具体类型（GC,Clair 等）。
- 根据 `job` 类型不同（`Scheduled，Periodic，Generic）`将其放入不同的调度队列中。分为三种分别为计划性任务、周期性任务以及默认类型的任务。
- 最后根据` req`中的`StatusHook`参数来判断是否开启`hook`功能

对于启动` job`方法来说，最为关键的部分在于将不同的 `kind`的` job`放入到不同的执行队列中。这里会调用` redis pool`的接口方法，来对`job`进行调度。这里定义了三种调度方法：
- Schedule：针对`Scheduled` job 进行调度
- PeriodicallyEnqueue: 针对`Periodic` job 进行调度
- Enqueue：针对`Generic` job进行调度

上述三个方法真正执行者是`GoCraftWorkPool`中对应的方法。在 `harbor`中`Generic`类型的job 比重最大，下面就来详细介绍一下此类型的` job`是如何进行调度的。检查 `job`的独立性，调用外部库`gocraft/work`的`Enqueue`的方法将`job `放入队列中，返回类型为` job`。这个` job`和` harbor`中定义的` job`类型有差别。主要使用` job`中的` ID,NAME和EnqueuedAt`来获取指工作任务的状态信息。完成任务状态的获取之后，通过实现了接口`JobStatsManager`的`RedisJobStatsManager`结构体的` save`方法异步的将` job `的状态信息保存起来并发送到`rjs.processChan`管道中

```go
item := &queueItem{
		Op:   opSaveStats,
		Data: jobStats,
	}
	
		rjs.processChan <- item

```
其他二种任务的调度方式，调用第三方库的`EnqueueIn`方法。


## env
这里定义了二个` context`：
- 一个是作为` root context`来使用，里面定义了可以共享的指标和系统控制通道，其中`root context`中还继承了具体的` job context`的接口方法。
- 而是一个`JobContext`，里面定义了一个具体的` job`都有哪些操作,其定义如下


```go
type JobContext interface {
	// Build the context based on the parent context
	//
	// dep JobData : Dependencies for building the context, just in case that the build
	// function need some external info
	//
	// Returns:
	// new JobContext based on the parent one
	// error if meet any problems
	// 使用依赖数据来构建新的 context，
	Build(dep JobData) (JobContext, error)

	// Get property from the context
	//
	// prop string : key of the context property
	//
	// Returns:
	//  The data of the specified context property if have
	//  bool to indicate if the property existing
	// 从 context 获取指定参数的值
	Get(prop string) (interface{}, bool)

	// SystemContext returns the system context
	//
	// Returns:
	//  context.Context
	SystemContext() context.Context

	// Checkin is bridge func for reporting detailed status
	//
	// status string : detailed status
	//
	// Returns:
	//  error if meet any problems
	Checkin(status string) error

	// OPCommand return the control operational command like stop/cancel if have
	//
	// Returns:
	//  op command if have
	//  flag to indicate if have command
	// 返回控制操作 stop/cancel
	OPCommand() (string, bool)

	// Return the logger
	GetLogger() logger.Interface

	// Launch sub jobs
	// 启动子 job
	LaunchJob(req models.JobRequest) (models.JobStats, error)
}
```

## errors
定义了多种类型的` job`错误代码以及处理函数

## job
此文件夹是` jobservice`中最重要的部分，这里定义了三种不同`job`的操作逻辑实现，主要分析镜像扫描的实现。

首先在job 的根目录下定义了` job `的执行状态信息，种类信息以及其接口需要实现的方法。具体实现如下：

```go
type Interface interface {
	// Declare how many times the job can be retried if failed.
	//
	// Return:
	// uint: the failure count allowed. If it is set to 0, then default value 4 is used.
	MaxFails() uint

	// Tell the worker pool if retry the failed job when the fails is
	// still less that the number declared by the method 'MaxFails'.
	//
	// Returns:
	//  true for retry and false for none-retry
	ShouldRetry() bool

	// Indicate whether the parameters of job are valid.
	//
	// Return:
	// error if parameters are not valid. NOTES: If no parameters needed, directly return nil.
	Validate(params map[string]interface{}) error

	// Run the business logic here.
	// The related arguments will be injected by the workerpool.
	//
	// ctx env.JobContext            : Job execution context.
	// params map[string]interface{} : parameters with key-pair style for the job execution.
	//
	// Returns:
	//  error if failed to run. NOTES: If job is stopped or cancelled, a specified error should be returned
	//
	// 真正的业务逻辑
	Run(ctx env.JobContext, params map[string]interface{}) error
}

```

在`impl`文件中，实现了二种` context`，`context.go`文件中定义的是在` main.go`中使用的，`default_context.go`文件中定义的是在` redis_job_wrapper.go`中使用，这是一个默认的的` job context`。

在`redis_job_wrapper.go`的`#243`行，如果此时的` jobcontext`为空则调用`DefaultContext`，不为空就使用`context.go`中的实现。`context.go`中的实现相比较于默认` context`来说多了从`Init()`函数用来从` adminserver`获取配置信息。`context`和`defaultContext`从它们都是` env`中 `jobcontext`接口的具体实现。


### DefaultContext
下面介绍一个`DefaultContext`中各个方法的实现。在`Build`方法中，传入的参数为`JobData`其中定义一个`job context`所需的依赖。

```go
// JobData defines job context dependencies.
type JobData struct {
	ID        string
	Name      string
	Args      map[string]interface{}
	ExtraData map[string]interface{}
}
```

通过注入的方式将`ExtraData`中含有的函数提出到` jobcontext`中。以`opCommandFunc`函数为例，先判断类型是否正确如果正确在使用反射的方式将接口类型转换为具体的函数类型，并赋值给`jobcontext`。

```go
if opCommandFunc, ok := dep.ExtraData["opCommandFunc"]; ok {
		// 判断 opCommandFunc 为函数类型
		if reflect.TypeOf(opCommandFunc).Kind() == reflect.Func {
			if funcRef, ok := opCommandFunc.(job.CheckOPCmdFunc); ok {
				// 将函数赋值给 job context，这里使用的是依赖注入的方式
				jContext.opCommandFunc = funcRef
			}
		}
	}
	if jContext.opCommandFunc == nil {
		return nil, errors.New("failed to inject opCommandFunc")
	}
```
其他的几个方法实现都比较简单，通过调用上述提取出各种类型` job`的具体处理函数来进行执行相关任务。

---
在` demojob.go`中展示了如果用户想要创建自己的` job`需要实现哪些逻辑，是一个很好的参考样本。

### utils
这里用来创建` registry`的` client`，用来在` jobservice`访问内部的` registry`。下面详细介绍一下在` jobservice`如何创建访问内部` registry`的客户端。

大体上分为二个步骤，一是构造访问内部 `registry` 的授权器二是构造访问内部` registry`的客户端，具体实现代码如下。


```go
func NewRepositoryClientForJobservice(repository, internalRegistryURL, secret, internalTokenServiceURL string) (*registry.Repository, error) {
	// 默认的传输通道
	transport := registry.GetHTTPTransport()
	// clair 的授权信息
	credential := httpauth.NewSecretAuthorizer(secret)
	// 使用刚刚构造的默认 http 传输通道以及授权信息。以及内部的 token 服务服务器 来构造授权器。
	authorizer := auth.NewStandardTokenAuthorizer(&http.Client{
		Transport: transport,
	}, credential, internalTokenServiceURL)

	uam := &UserAgentModifier{
		UserAgent: "harbor-registry-client",
	}

	// 使用上述信息构造 内部registry 的访问客户端。
	return registry.NewRepository(repository, internalRegistryURL, &http.Client{
		Transport: registry.NewTransport(transport, authorizer, uam),
	})
}
```

`GetClient()`用在扫描全部镜像时创建访问` core`中的` registry`，在`all.go`中使用。

`GetTokenForRepo()`用来为 `clair` 访问 `registry` 提供 `token`信息。

## scan job
在 harbor 中定义了二种镜像扫描的方式
- `clair_job.go`中定义的扫描方式是只扫描单一指定镜像
- `all.go`中定义的扫描方式是一种全局的扫描，会扫描仓库中所有的镜像


### clair_job.go
不出意外，这里的扫描任务也实现了` Interface`接口，定义了一个任务需要哪些方法。其中最重要的就是` run()`方法的实现。我们先从`run()`方法的调用链入手，在深入到其具体实现。

在` clair_job.go`中的` run()`方法被`redis_job_wrapper.go`中的` run()`方法调用，这是一个对` redis_pool.go`文件的包装。`redis_pool.go`对` redis`实际的一些操作都是通过这个包装来具体实施的。

`redis_job_wrapper.go`中的` run()`被`redis_pool.go`中的`RegisterJob()`调用。而`RegisterJob()`被`Bootstrap.go`中的`loadAndRunRedisWorkerPool()`调用，其又是被`LoadAndRun()`调用。

在`jobservice`初始的过程中，会注册` DemoJob`来检查各种类型的` job`是否能正常运行，在` redis`中的信息如下。
![](https://ws1.sinaimg.cn/large/006tNc79ly1g37z5g2lrwj319y0n0jt6.jpg)

---
在业务的执行函数中，传入了以下函数。其中`env.JobContext`中主要是3 个匿名函数的实现
```
 Run(ctx env.JobContext, params map[string]interface{})
```

传入的第二个参数是扫描` job`提交给` jobservice`的，其结构体如下

```go
// ScanJobParms holds parameters used to submit jobs to jobservice
type ScanJobParms struct {
	JobID      int64  `json:"job_int_id"`
	Repository string `json:"repository"`
	Tag        string `json:"tag"`
	Digest     string `json:"digest"`
}

```


clair 的结构体定义如下：

```go
type ClairJob struct {
	registryURL   string
	secret        string
	tokenEndpoint string
	clairEndpoint string
}
```

在` run()`函数中
- 首先调用的` init()`函数用来获取` ClairJob`结构体中定义的参数的数据。
- 解析传入参数，将参数信息转化为`ScanJobParms`结构体类型
- 为`jobservice`创建访问存储库的` client` **（因为这里是用来扫描指定镜像的，所以创建的是访问`Repository`的客户端）**
- 请求`registry`获取指定镜像的` manifest`。
- 创建访问`Repository`的` token`信息，传入的参数有需要方法存储库的名称，密码以及` token`服务器的地址
- **`prepareLayers(payload, cj.registryURL, jobParms.Repository, token)`使用镜像的 `manifest`，需要访问的镜像的`registry`，存储镜像的`Repository`以及` token 信息`。通过这些信息准备好需要扫描的` layer`，最后将这些 `layer`发送给` clair`进行扫描**

    `prepareLayers()`函数中构造出了供` clair`使用的镜像` layer`信息其具体定义如下
    
    ```go
    type ClairLayer struct {
    	Name           string            `json:"Name,omitempty"`
    	NamespaceNames []string          `json:"NamespaceNames,omitempty"`
    	Path           string            `json:"Path,omitempty"`
    	Headers        map[string]string `json:"Headers,omitempty"`
    	ParentName     string            `json:"ParentName,omitempty"`
    	Format         string            `json:"Format,omitempty"`
    	Features       []ClairFeature    `json:"Features,omitempty"`
    }
    
    
    // ClairFeature ...
    type ClairFeature struct {
    	Name            string               `json:"Name,omitempty"`
    	NamespaceName   string               `json:"NamespaceName,omitempty"`
    	VersionFormat   string               `json:"VersionFormat,omitempty"`
    	Version         string               `json:"Version,omitempty"`
    	Vulnerabilities []ClairVulnerability `json:"Vulnerabilities,omitempty"`
    	AddedBy         string               `json:"AddedBy,omitempty"`
    }
    
    // ClairVulnerability ...
    type ClairVulnerability struct {
    	Name          string                 `json:"Name,omitempty"`
    	NamespaceName string                 `json:"NamespaceName,omitempty"`
    	Description   string                 `json:"Description,omitempty"`
    	Link          string                 `json:"Link,omitempty"`
    	Severity      string                 `json:"Severity,omitempty"`
    	Metadata      map[string]interface{} `json:"Metadata,omitempty"`
    	FixedBy       string                 `json:"FixedBy,omitempty"`
    	FixedIn       []ClairFeature         `json:"FixedIn,omitempty"`
    }
    ```
    
    在`prepareLayers()`中提取出镜像的` manifest`信息，对其处理。通过遍历`manifest.References()`来提取镜像每一层的信息，这些信息主要为一下四种：名称`(d.Digest)`,头`(tokenHeader)`,格式`(docker)`以及层的路径`(%s/v2/%s/blobs/%s", endpoint, repository, digest)`。在提取每一层的同时，也构造出其父层。最后全部存储在` layers`中返回
- 创建访问` clair`的客户端，传入了二个参数。`clair.NewClient(cj.clairEndpoint, loggerImpl)`
- 遍历每一层` layers`，调用` clairClient`的`ScanLayer()`方法来对镜像层进行扫描。这个方法对于` clair`来说相当于一个启动命令，这里不获取返回结果。
- 获取扫描结果，更新数据库中的信息


**问题：clair 是主要根据` manifest`中提供的镜像层的信息来扫描的，那么` clair`是如何获取到镜像层的具体元数据呢？
在` clairLayer`中定义每一`layer`数据` blob`的具体访问地址，`clair`在扫描对应层是只需要访问其地址即可。**

### all.go
查询数据库和` registry`获取所有镜像的信息，然后调用` harbor`的` API`来扫描其中的每一个镜像。

这里的实现比较简单，首先调用初始化函数获取相关的配置信息。然后访问数据库获取其中存储的`Repositories`信息。启动扫描全局镜像的任务在二个循环中完成。

1. 第一次循环中，对`Repositories`进行遍历，创建访问`Repositories`的客户端使用`repoClient`获取此`Repositories`中镜像的标签`(tags)`。
2. 第二次循环中对` tags`进行遍历，以` tags`为颗粒度对镜像进行扫描

通过上述二层循环，即可完成对整个 harbor 存储镜像的扫描工作。