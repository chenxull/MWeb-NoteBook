# MapReduce 

## MapReduce 相关问题

**What will likely limit the performance?**

```
网络带宽
```

**How does detailed design reduce effect of slow network?**

```
利用GFS把输入数据保存在处理数据的计算机集群上。数据被分为多个64MB的数据包，
在不同的机器上保存多个副本。 

MR master在分配任务时，会尽可能的让 worker 与其需要处理的数据在同一个局域网内，方便读取。所以通过这种设计，在大部分时候MR的数据只会杂局域网内传递，不会消耗网络带宽
```


**How do they get good load balance?**

```
任务数量是 worker 的数倍，worker 在完成任务之后，会被安排新的工作。
能者多劳的思想，所以 worker 都能在差不多的时间内完成工作。
```

**What about fault tolerance?**


```
1. worker A失效：在规定的时间内，A没有响应 master 的应答，失效的情形分三种
    - A 所有已经完成的 map 任务都会被重新安排到其他 worker 执行。Map 任务的结果仅仅保存在 A 的本地磁盘上，A 失效后，执行 reduce 任务的 worker 无法读取结果，所以 master 会安排 B 重新执行 Map 任务。任务结果会保存在B 上。这个时候 master 通知所有正在执行 reduce 任务的 worker，以前存放在 A 上的结果，现在存储在B 上了
    - A 正在执行的 Map 或 Reduce 任务，会被重新安排到其他 worker 执行
    - A所有已经完成的Reduce 任务不会被重新执行， 因为 Reduce 任务的结果保存在 GFS 上，不在本地磁盘上存储，所以不需要重新执行
2. master 失效： 在规定的时间内，master 没有响应
    - 通知 client 任务失败
3. 失效存在的语义表示
    - 第一个被完成的 map 任务才会被记录在 master 中
    - reduce 任务的结果重命名必须是原子操作，才能保证最终结果是有同一个 reduce 任务完成的，独占任务。
```

**Other failures/problems?**


```
What if the master gives two workers the same Map() task?
  先完成的工作成果会被 master 记录在案
What if the master gives two workers the same Reduce() task?
  依靠底层文件系统提供的原子化重命名操作，保证 reduce 任务完成的结果只有一个
What if a single worker is very slow -- a "straggler"?
  使用 backup task 机制，所有没有被标记为“完成”的任务都会被分配出去。通过重复指派任务，可以有效避免任务堆积。
What if a worker computes incorrect output, due to broken h/w or s/w?
  重新计算
What if the master crashes?
  通知 client 处理
```

**为什么MapReduce 扩展性很好**

```
Map() 函数可以并行运行，因为它们之间不会进行交互，reduce()操作也是这样。 唯一的交互 点在于map 和 reduce 之间的 shuffle操作。

所以可用通过买大量的电脑来扩容。
```