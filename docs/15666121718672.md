# STAR 介绍模型


## 简短的项目背景
环境资源容器虚拟化镜像安全机制研究，这是一个国家重点研发项目的一个子课题，也是我在研究生期间主要负责的项目。这个项目的主要目标就是为超算中心环境中的软件资源上云，提供了底层服务支持。

主要是从镜像库的构建角度切入，研究镜像仓库的安全机制和系统实现，实现安全镜像仓库的管理平台。

## 自己完成的任务
1. 调研现有技术，镜像的基本管理功能基于官方的 registry 做二次开发。
2. 基本的架构设计，设计组件之间的交互逻辑
3. 主要功能模块的编写，实现了镜像漏洞信息的收集，和可视化处理。针对扫描出的结果，限制镜像的push/pull 操作。被删除镜像的垃圾回收。

## 为了完成任务自己做了哪些工作，是怎么做的(还需要增加)

1. 在设计整个系统时，考虑到官方的 registry 已经实现了对于镜像的基本管理功能，同时 registry v2 版本中，可以通过 HTTP API 对私有仓库进行操作。基于以上特点，选择了官方 registry 作为镜像管理的核心。主要使用了 registry 的 webhook，镜像管理，token 认证等功能。

2. 同时为了，对接容器生态圈，选择 golang 为后端的主要开发语言。使用的 beego 框架作为后端框架，主要使用了其提供的 路由，orm等功能。

3. 镜像漏洞扫描的功能，使用 clair 来实现。大致思路就是首先获取执行镜像每一个数据，扫描指定的文件夹，获取其中所拥有的软件。对比 CEV 数据库，查看这些软件官方维护的漏洞信息，将这些信息可视化出来，供系统管理员做出各种决策。
4. 在部署方面，各个功能模块进行容器化处理，部署时直接使用 docker-compose 进行快速部署。




## 自己的贡献
完成后端系统核心功能的开发
### 对于整体系统架构的设计
整个系统分为以下 组件：
- 前端
- nginx 组件：用来对发送来的请求做代理
- 核心组件：服务的核心，前端发送来的请求经过 nginx 转发后，会来到这里。主要负责用户登录的认证，项目的创建，镜像的删除，镜像漏洞的扫描，镜像垃圾回收等功能。这些服务都是通过Restful API 的形式，暴露给前端进行调用
- worker 组件：为了使组件之间松耦合，将镜像的垃圾回收以及漏洞扫描任务的具体执行，从核心组件中剥离出来，单独交给 worker 组件来执行
- clair 组件：第三方的工具，用来对镜像的漏洞数据进行扫描，并将扫描的结果存储在数据库中。谈谈具体是如何扫描镜像的，
- 日志收集组件

### api 设计

核心组件对外暴露的 API 大致分为 5 种。

### 对于请求的处理
1. 路由过滤：验证请求中携带的账号信息，进行认证
2. 请求以 context 的形式传递，在完成基本的认证之后，会为这个 context 带上用户的基本信息(用户所具有的权限)以及项目管理器。供后续的使用 

### 安全性上的设计
1. registry 开启了 token 认证功能
2. 针对扫描的结果，来限制镜像的 push/pull
3. 上传镜像的自动扫描



## 难点

### token 授权服务器
2 个作用，登录 registry 认证，基于角色的访问控制。

docker pull/push 的流程

1. **认证过程**：
    - 如果docker registry需要进行授权时，registry将会返回401 Unauthorized响应，同时在返回的头信息中包含了docker client如何进行认证的信息
    - docker client根据registry返回的信息，向**授权服务器**发送请求获取**认证token**
    - **授权服务器** 则根据去验证提交的用户信息，查询数据库中是否存在相关用户信息
    - **授权服务器** 将会根据查询的用户信息，生成token令牌，以及当前用户所具有的相关权限信息
    - docker client携带**授权服务器**返回的token令牌再次尝试访问docker registry.
    - registry验证用户提交的token令牌信息，通过后则开始镜像的pull或者push动作


在启动 registry 的过程，从`/etc/docker/registry/config.yml`读取所有的配置信息，这里主要是对 auth 信息配置。

- `realm`认证服务的地址
- `service`用于请求授权服务的携带的service名称
- `issuer`registry 信任的授权服务器名称
-  `rootcertbundle` 用户验证token签名的**公钥文件**

```
auth:
  token:
    issuer: cnic-token-issuer
    realm: $public_url/service/token
    rootcertbundle: /etc/registry/root.crt
    service: cnic-registry
```

Docker Client提供用户输入用户名和密码后向授权服务器的Endpoint发送请求，只需要从http head中获取登录的用户名和密码，并且验证登录信息的合法性，同时根据业务数据返回用户的实际权限(pull, push)即可.


#### 如何生成符合Docker Registry规范的Json Web Token详解
使用 openssl 生成用户加密的公私钥，此时我们将得到两个文件加密文件**root.cert**和**root.key**。

在Docker Registry端，root.cert对应docker registry的auth.token.rootcertbundle配置项，用户验证**docker client**请求时提供的token是否合法.

在授权服务器端，当拦截到到认证请求信息后。首先是对请求做一些基本处理，判断用户的操作权限。根据以下 3 步，生成token 内容。

1. 生成jwt的Header信息
    
    ```
    {
    "typ": "JWT",
    "alg": "ES256", 对应私钥文件的加密方式
    "kid": "PYYO:TEWU:V7JH:26JV:AQTZ:LJC3:SXVJ:XGHA:34F2:2LAQ:ZRMK:Z7Q6"
    根据docker提供的规则生成公钥文件的kid,registry会根据同样的算法获取公钥的kid,如果匹配失败则认证失败
}
    ```
2. 设置jwt的payload信息Claim Set,关键信息就是 access 字段
    
    ```
    {
        "iss": "Auth Service", //需要注意必须与auth.token.issuer配置保持一致
        "sub": "some id", //根据业务系统的规则自定义生成即可
        "aud": "Docker registry",// 从请求的service参数获取
        "exp": 1415387315, //过期时间
        "nbf": 1415387015, // not before 可选参数
        "iat": 1415387015, // 正式发行时间
        "jti": "tYJCO1c6cnyy7kAn0c7rKPgbV1H1bFws", //随机生成即可
        // access根据请求的scope获取，当然业务系统要判断用户的实际权限并在actions中放回
        "access": [
            {
                "type": "repository",
                "name": "samalba/my-app",
                "actions": [
                    "pull",
                    "push"
                ]
            }
        ]
    
        }
    ```
3. 最后使用auth.key私钥进行签名



### 项目权限管理
以项目颗粒度，对镜像仓库镜像管理。在一个项目下面，会有三种不同的角色，项目管理员1，开发人员 2，普通用户 3。 

项目管理员对这个项目具有最高权限，可以删除整个项目，同时具有低镜像的 push/pull权限；开发人员只具有 push/pull 权限；普通人员只具有 pull 权限。


这一功能是通过内部的 token 服务实现的，内部的 token服务除了用于**用户登录 registry**生成 token 令牌外。还用来检查当前用户类型，对于某个镜像具有何种访问权限。

在 token 服务中定义了一个`repository`过滤器，这个过滤器会解析docker 客户端发出的请求。在这个请求中，最为关键的就是` scope`字段，这个字段中包含了所访问镜像的详细名称，以及操作类型。

```
scope="repository:samalba/my-app:pull,push"
```

在这个过滤器中，首先会获取镜像名，以及镜像所在的项目组。因为请求`context`中含有用户信息和项目管理器(在一个请求最开始进入核心组件时，加入到 context 中的)。通过**项目名和用户信息查询数据库中的数据**，获取当前用户在这个项目中具有何种操作权限。角色编号为 1 代表具有所有操作权限。

>查询细节: 在表 role(定义了 3 种用户的权限) 和 project_member（定义了项目中所包含的用户） 表中使用 project_id ,user_id 查询用户的 角色信息。


## 亮点  worker 节点的实现

特色功能：
1. 支持 webhook
2. 参考 kubernetes 中控制器模式的思想，来根据任务的状态，对任务的执行做调度。
3. 真正任务的执行，使用的是 gocraft/worker 框架。


在这个 gocraft 框架的基础上，增加了对任务生命周期的管理 以及 webhook 功能，增强了job 运行的成功性。


### 控制器模式

为了实现以**状态核心**的任务处理，给任务定义了 6 种不同的状态，大致分为二种类型：运行态和最终态。运行态分为三种：`pending 0`，`scheduled 1`，`running 2`。最终态也有三种，不过一个任务只会有一个最终态：`stoped 3` ,`Error 3`,`Success 3`。


在最开始任务都是属于` pending`状态，目标状态为`Success`。

从任务的控制层面上来说，任务定义了二种控制器。
1. 其一，**任务管理器**。用来获取任务和存储任务状态
2. 其二，**任务生命周期管理器**。是根据获取到当前任务信息的状态，执行相应的处理逻辑

具体是怎么实现了，我举一个例子，讲解一下整个的处理流程。
### 介绍完整的工作流程

#### 任务到达 worker 组件

当一个镜像扫描任务发送到 worker 组件之后，会首先验证该类型的 job 是否在gocraft worker 框架中注册过。如果没注册直接返回错误信息；如果注册过就放到的工作队列中。<!--这个工作调度队列中任务的执行使用 gocraft 框架实现。-->

工作队列使用 redis 进行实现，通过 `LPUSH` 命令将任务信息存储在 redis 中。在将任务信息放入到 redis 的同时，会返回这个任务的基本信息（比如说 job_id，job 名称，配置的 webhook 等信息），其中最为关键的是将**任务的初始状态设置为 pending。**这个任务的状态，就是后面执行过程调度的核心。

完成上述将任务放入到工作队列之后，会调用**任务管理器**，将 job 的信息状态存储起来。任务管理器会调用**任务生命周期管理器**将任务状态等信息存储到` redis`中。因为任务状态信息由多条` k-v`对组成的，所以使用事务命令` MULTI`+`HMSET`+`EXEC`的方式，将数据存储到` redis `中。确保数据在存储的过程中，不会出现意外。


上面是任务发送到 worker 组件时放入到工作队列的处理过程。


#### 任务的执行

任务的执行是使用` gocraft`来实现的，在启动 worker 组件时，回将任务类型的名称，最大失败尝试次数，和最关键的**任务执行函数**，注册到` gocraft`中。

这里简单的介绍一下` gocraft worker`的工作原理。在启动 gocraft worker 时，主要是启动二个协程分别
- gocraft worker 的主逻辑，从 redis 队列中获取可执行的任务
- gocraft worker 的观察者，用来监听任务的执行。

worker 的主逻辑就是一个 loop 循环，通过一个内置好` lua`脚本，从 redis 中的工作队列获取 可执行的任务。在获取到任务的信息之后，就会调用` process`方法，因为之前注册过任务的执行函数。**这里任务实际的执行，就是调用之前注册的任务启动函数**。

在**运行函数中**，首先就是根据 任务的id 创建一个 **新的任务生命周期管理器**。通过任务的生命周期管理器，先获取 redis 中存储任务的详细信息。这里使用的是` redis`的` HGETALL`方法，key 为` namespace+jobid`，这样获取到之前存入到 redis 中的全部任务信息。

有了任务运行所需要的源数据，在启动任务执行逻辑之前，将任务的状态目标状态设置为` running`。这是**任务生命周期管理器就会**从 `redis`中使用` HMGET`方法获取当前任务的状态信息，通过将任务的最新状态与目标状态进行比较，如果从 redis 中获取的最新状态对应的值大于目标` running`状态的值，会直接返回状态不匹配。如果状态相同会返回 nil，从 redis 中获取的状态落后于目标状态，直接将任务的状态值更新为目标状态，并存储到 redis 中。

当任务状态成功的设置为目标状态之后，会检测对应的状态是否设置了 webhook，这个 webhook 也就是将任务的一些基本信息发送给核心组件，用来更新数据库任务信息，或者触发一些新的流程。

在运行函数中，定义了一个` defer`函数，这个函数主要是根据任务执行完成后返回err 的情况，以及通过 tracker 获取到的 job 状态信息，来执行对应的操作。
- 如果返回的 err 不为空，就通过**任务声明周期管理器**将任务的状态设置为 error并返回。
- 如果任务的状态为 stopped(在前端用户执行一个任务时，可以发送停止任务执行请求，这个请求会将该任务的状态标记为 stopped)，返回对应的信息。
- 最后，将任务状态设置为 success，并启动任务执行成功时的 webook，将最新的状态发送到核心组件中。


目前实现的镜像扫描任务是立即执行的，在接下来的开发中，可以增加定期执行的镜像扫描任务，这种基于控制器为核心的任务控制可以更有效的对任务状态进行维护。


## 最大的问题 2 如何 registry 中的数据与核心组件之间的交互。

在实现用户使用 docker push上传镜像到仓库时，前端界面的项目中就会展示出刚刚上传来的镜像信息这个功能时。最初的想法是核心组件获取到`/v2`的请求时，直接通过对请求的解析，来获取镜像的基本信息，这些信息包括**镜像名，tag，项目名，digest**。   这样方法虽然可以获取到镜像的基本信息，但是如果在传输过程中失败，实际上 registry 中并没有成功接收到镜像数据，但是前端界面还是显示了这个镜像的信息。

后来在查询 registry 文档时，其支持 webhook 功能。简单来说，就是 registry 支持将处理的信息 以 json 格式发送出去。比如说对于 push 指令，当镜像成功上传到 registry 之后，会将这个镜像的基本信息以` events`发送对配置好的 endpoint 上去。所以在启动registry 的时候，给其配置了`webhook`地址，这个` events`会发送给 **核心组件处理**。

```json
{
  "events":[
    {
      "id": "a6089916-c2b3-4103-aa2d-40db93f10ee2",
      "timestamp": "2017-10-13T02:58:17.285607811Z",
      "action": "push",
      "target": {
        "mediaType": "application/vnd.docker.distribution.manifest.v2+json",
        "size": 1569,
        "digest": "sha256:ddf13beebac2a486e5f9a7fe77fbcc3a20e3d632c006961430d4cd2271aefde2",
        "length": 1569,
        "repository": "arashivision/redis",
        "url": "http://localhost:5000/v2/arashivision/redis/manifests/sha256:ddf13beebac2a486e5f9a7fe77fbcc3a20e3d632c006961430d4cd2271aefde2",
        "tag": "3.2-alpine"
      },
      "request": {
        "id": "8cb085ed-fcaa-481a-bd10-3ed491761641",
        "addr": "172.17.0.1:52832",
        "host": "localhost:5000",
        "method": "PUT",
        "useragent": "docker/17.09.0-cego/go1.8.3 git-commit/afdb6d4 kernel/4.9.49-moby os/linux arch/amd64 UpstreamClient(Docker-Client/17.09.0-ce \(darwin\))"
      },
      "actor": {

      },
      "source": {
        "addr": "9e566ba1324c:5000",
        "instanceID": "1f0100e8-89de-42f8-b9bf-534b6c7fce23"
      }
    }
  ]
}
```

在核心组件中专门设置了`/service`API ，用来接受其他组件的通知服务。对于镜像上传来说，当镜像成功上传到 registry 之后，registry 会将这个镜像的基本信息 以` events`的形式，发送到核心组件的`/service/registry`API。

核心组件 首先会对` events`进行处理，将 registry 传来数据转化为对应的` events`结构体。主要是获取 events 结构体中关于**镜像名，项目名，tag，操作类型(pull/push)**等信息。

有了上述的基本信息之后，会启动一个协程将此次对 镜像仓库操作的信息存储到数据库中，作为访问日志。同时针对操作的类型(Push/Pull),采取不同的操作。

对于**Push 操作来说，就会将镜像的基本信息存入到数据库中，这样前端就可以正确的显示相关信息。**同时使用这种数据同步方法之后，带来的另外一个好处就是可以对每一个上传的镜像，自动开启镜像扫描功能。