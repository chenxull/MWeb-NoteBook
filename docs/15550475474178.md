# Raft 论文

>本文为著名的 RAFT 一致性算法论文的中文翻译，论文名为《In search of an Understandable Consensus Algorithm (Extended Version)》(寻找一种易于理解的一致性算法)


## 摘要
Raft 是一种用来管理日志复制的一致性算法。它和 Paxos 的性能和功能是一样的，但是它和 Paxos 的结构不一样；这使得 Raft 更容易理解并且更易于建立实际的系统。为了提高理解性，Raft 将一致性算法分为了几个部分，例如领导选取（leader selection），日志复制（log replication）和安全性（safety），同时它使用了更强的一致性来减少了必须需要考虑的状态。从用户学习的结果来看，Raft 比 Paxos 更容易学会。Raft 还包括了一种新的机制来使得动态改变集群成员，它使用重叠大多数（overlapping majorities）来保证安全。

## 1引言
在设计 raft 的过程中我们应用了很多技巧来提升理解性，包括算法分解(领导选取，日志复制，安全性)和减少状态(相对于P axos,raft减少了非确定性的程度和服务器互相不一致的方式)

raft 算法和现在一些已有的一致性算法有很多地方相似,但是其有几个新的特征:
- 强领导者:Raft 使用一种比其他算法更强的领导形式。例如，日志条目只从领导者发送向其他服务器。这样就简化了对日志复制的管理，使得 Raft 更易于理解。
- 领导选取:Raft 使用随机定时器来选取领导者。这种方式仅仅是在所有算法都需要实现的心跳机制上增加了一点变化，它使得在解决冲突时更简单和快速。
- 成员变化:Raft 为了调整集群中成员关系使用了新的联合一致性（joint consensus）的方法，这种方法中大多数不同配置的机器在转换关系的时候会交迭（overlap）。这使得在配置改变的时候，集群能够继续操作。

这篇论文剩下的部分会讲如下内容：复制状态机（replicated state machine）问题（第2节），讨论 Paxos 的优缺点（第3节），讨论我们用的为了达到提升理解性的方法（第4节），陈述 Raft 一致性算法（第5~8节），评价 Raft 算法（第9节），对相关工作的讨论（第10节）。

## 2.复制状态机
一致性算法是在复制状态机的背景下提出来的。在这个方法中，在一组服务器的**状态机产生同样的状态的副本**,因此即使有一些服务器崩溃了这组服务器还能继续运行.复制状态机在分布式系统中被用于解决许多有关容错的问题.例如，GFS，HDFS还有 RAMCloud 这些大规模的系统都是用一个**单独的集群领导者，使用一个单独的复制状态机来进行领导选取和存储配置信息来应对领导者的崩溃**。使用复制状态机的例子有 Chubby 和 ZooKeeper。

![](https://ws4.sinaimg.cn/large/006tNc79ly1g1zw7htfrwj30ns0gogos.jpg)
如图所示,复制状态机是通过**复制日志**来实现的.每台服务器保存着一份日志,日志中包含一系列的命令,状态机会按照顺序执行这些命令. 因为每台计算机的状态机都是确定的,所以每个状态机的状态都是相同的,执行的命令都是相同的,**最后的执行结果也就是一样的.**

如何保证复制日志的一致性就是一致性算法的工作。在一台服务器上，一致性模块接受 client 的命令并把命令加入到它的日志中。它和其他服务器上的一致性模块进行通信确保每一个日志最终包含相同序列的请求,即使一些服务器宕机了。 一旦这些命令被正确的复制了，每个服务器的状态机都会按照同样的顺序去执行它们，然后将结果返回给 client 。最终，这些服务器看起来就像一台可用的状态机。

应用于实际系统的一致性算法一般有以下特性：
- 确保安全性（从来不会返回一个错误的结果），即使在所有的非拜占庭（Non-Byzantine）情况下，包括网络延迟、分区、丢包、冗余和乱序的情况下。
- 高可用性，只要集群中的大部分机器都能运行，可以互相通信并且可以和客户端通信，这个集群就可用。因此，一般来说，一个拥有 5 台机器的集群可以容忍其中的 2 台的失败（fail）。服务器停止工作了我们就认为它失败（fail）了，没准一会当它们拥有稳定的存储时就能从中恢复过来，重新加入到集群中。
- 不依赖时序保证一致性，时钟错误和极端情况下的消息延迟在最坏的情况下才会引起可用性问题。
- 通常情况下，一条命令能够尽可能快的在大多数节点对一轮远程调用作出相应时完成，一少部分慢的机器不会影响系统的整体性能。


### 3.Paxos算法的不足
Paxos 首先定义了一个能够达成单一决策一致的协议，例如一个单一复制日志条目（single replicated log entry）。我们把这个子集叫做单一决策 Paxos（single-decree Paxos）。之后 Paxos通过组合多个这种协议来完成一系列的决策，例如一个日志（multi-Paxos）。Paxos 确保安全性和活跃性（liveness），并且它支持集群成员的变更。它的正确性已经被证明，通常情况下也很高效。

Paxos 有两个致命的缺点：
-  Paxos 太难以理解，我们假定 Paxos 的晦涩来源于它将单决策子集作为它的基础。单决策（Single-decree）Paxos 是晦涩且微妙的：它被划分为两个没有简单直观解释的阶段，并且难以独立理解。正因为如此，它不能很直观的让我们知道为什么单一决策协议能够工作。为多决策 Paxos 设计的规则又添加了额外的复杂性和精巧性。我们相信多决策问题能够分解为其它更直观的方式。
-  Paxos 的第二个缺点是它难以在实际环境中实现。其中一个原因是，对于多决策 Paxos （multi-Paxos） ，大家还没有一个一致同意的算法。Lamport 的描述大部分都是有关于单决策 Paxos （single-decree Paxos）；他仅仅描述了实现多决策的可能的方法，缺少许多细节。

另外，Paxos 的结构也是不容易在一个实际系统中进行实现的，这是**单决策问题分**解带来的又一个问题。从许多日志条目中选出条目然后把它们融合到一个序列化的日志中并没有什么好处，还增加的复杂性。围绕着日志来设计一个系统是更简单、更高效的：**新日志按照严格的顺序添加到日志中去**。

另外一个问题：**Paxos 使用对等的点对点的实现作为它的核心**（尽管它最终提出了一种弱领导者的形式来优化性能）。这种方法在只有**一个决策**被制定的情况下才显得有效，但是很少有现实中的系统使用它。如果要做许多的决策，选择一个领导人，由领带人来协调是更简单有效的方法。

在实际的系统应用中和 Paxos 算法都相差很大。所有开始于 Paxos 的实现都会遇到很多问题，然后由此衍生出了许多与 Paxos 有很大不同的架构。这是既费时又容易出错的，并且理解 Paxos 的难度又非常大。理论上很好证明，但是实现上的价值就远远不足了。

## 易于理解的设计
设计 Raft 的目标有如下几个：
- 它必须提供一个完整的，实际的基础来进行系统构建，为了减少开发者的工作量
- 他必须在所有的情况下能够保证安全可用
- 常规操作必须高效
- **最重要的目标是：易于理解，它必须使得大多数人能够很容易的理解；**
- 它必须能让开发者有一个直观的认识，这样才能使系统构建者们去对它进行扩展。

在设计 Raft 的过程中，我们不得不在许多种方法中做出选择。当面临这种情况时，我们通常会权衡可理解性：
- 每种方法的可理解性是如何的？（例如，它的状态空间有多复杂？它是不是有很细微的含义？）
- 它的可读性如何？
- 读者能不能轻易地理解这个方法和它的含义？

我们意识到对这种可理解性的分析具有高度的主观性；尽管如此，我们使用了两种适用的方式。
1. 第一种是众所周知的问题分解：我们尽可能将问题分解成为若干个可解决的、可被理解的小问题。例如，在 Raft 中，我们把问题分解成为了**领导选取（leader election）、日志复制（log replication）、安全（safety）和成员变化（membership changes）**。
2. 第二种方法是通过**减少需要考虑的状态数量将状态空间简化**，这能够使得整个系统更加一致并且尽可能消除不确定性。
    -  特别的，日志之间不允许出现空洞，并且 raft 限制了日志不一致的可能性。
    - 尽管在大多数情况下，我们都都在试图消除不确定性，但是有时候有些情况下，不确定性使得算法更易理解。尤其是，随机化方法使得不确定性增加，但是它减少了状态空间。**我们使用随机化来简化了 Raft 中的领导选取算法**。


## Raft 一致性算法
这个表是算法的总结版本,表格中的这些元素将会在这一章剩下的部分中分别进行讨论。
![](https://ws1.sinaimg.cn/large/006tNc79ly1g1zze64154j30u00y1dwa.jpg)

1. Raft 通过首先选出一个领导人来实现一致性，然后给予领导人完全管理复制日志（replicated log）的责任。
2. 领导人接收来自客户端的日志条目，并把它们复制到其他的服务器上，领带人还要告诉服务器们什么时候将日志条目应用到它们的状态机是安全的。
3. 通过选出领导人能够简化复制日志的管理工作。例如，领导人能够决定将新的日志条目放到哪，而并不需要和其他的服务器商议，数据流被简化成从领导人流向其他服务器。
4. 如果领导人宕机或者和其他服务器失去连接，就可以选取下一个领导人。

**通过选出领导人，Raft 将一致性问题分解成为三个相对独立的子问题：**

1. **领导人选取（Leader election）**： 在一个领导人宕机之后必须要选取一个新的领导人（5.2节）
2. **日志复制（Log replication）**： 领导人必须从客户端接收日志然后复制到集群中的其他服务器，并且强制要求其他服务器的日志保持和自己相同
3. **安全性（Safety）**： Raft 的关键的安全特性是 表-3 中提到的状态机安全原则（State Machine Safety）:如果一个服务器已经将给定索引位置的日志条目应用到状态机中，则所有其他服务器不会在该索引位置应用不同的条目。5.4节阐述了 Raft 是如何保证这条原则的，解决方案涉及到一个对于选举机制另外的限制，这一部分会在 5.2节 中说明。

### raft 基础
一个 Raft 集群包括若干服务器；对于一个典型的 5 服务器集群，该集群能够容忍 2 台机器不能正常工作，而整个系统保持正常。在任意的时间，每一个服务器一定会处于以下三种状态中的一个：**leader**、**candidate**、**follower**。

![](https://ws1.sinaimg.cn/large/006tNc79ly1g217alliwdj30mg0dk41o.jpg)

正常情况下，只有一个服务器是leader，剩下的服务器是follower。followers是被动的：他们不会发送任何请求，只是响应来自**leader**和**candidate**的请求。leader 处理所有来自 client 的请求（如果一个 client与 follower 进行通信，follower 会将信息发送给领leader）。candidate 是用来选新的 leader 的。上图是他们之间的状态转换。

Raft 中的服务器通过远程过程调用（RPC）来通信，基本的 Raft 一致性算法仅需要 2 种 RPC。
- RequestVote RPC 是候选人在选举过程中触发的（5.2节
- AppendEntries RPC 是领导人触发的，为的是复制日志条目和提供一种心跳（heartbeat）机制（5.3节）。
- 第7章加入了第三种 RPC 来在各个服务器之间传输快照（snapshot）。如果服务器没有及时收到 RPC 的响应，它们会重试，并且它们能够并行的发出 RPC 来获得最好的性能。

### 5.2 leader 选举
Raft 使用一种心跳机制(hearbeat)来触发leader 的选取.在服务器启动时,它们会初始化为**follower**。服务器会一直保持follower的状态只要它们能够收到来自领导人或者候选人的有效 RPC。领导人会向所有追随者周期性发送心跳（**heartbeat**，不带有任何日志条目的 AppendEntries RPC）来保证它们的领导人地位。**如果一个追随者在一个周期内没有收到心跳信息，就叫做选举超时（election timeout）,然后它就会假定没有可用的领导人并且开始一次选举来选出一个新的领导人。**

为了开始选举，一个追随者会自增它的当前任期并且转换状态为候选人。然后，它会给自己投票并且给集群中的其他服务器发送 RequestVote RPC。一个候选人会一直处于该状态，直到下列三种情形之一发生：
- 它赢得了选举；
- 另一台服务器赢得了选举；
- 一段时间后没有任何一台服务器赢得了选举

一个候选人如果在一个任期内收到了来自集群中大多数服务器的投票就会赢得选举。在一个任期内，一台服务器最多能给一个候选人投票，按照先到先服务原则（first-come-first-served）.一旦有一个候选人赢得了选举，它就会成为领导人。然后它会像其他服务器发送心跳信息来建立自己的领导地位并且组织新的选举。

当一个候选人等待别人的选票时，它有可能会收到来自其他服务器发来的声明其为领导人的 AppendEntries RPC。如果这个领导人的任期（包含在它的 RPC 中）比当前候选人的当前任期要大，则候选人认为该领导人合法，并且转换自己的状态为追随者。如果在这个 RPC 中的任期小于候选人的当前任期，则候选人会拒绝此次 RPC， 继续保持候选人状态。

第三种情形是一个候选人既没有赢得选举也没有输掉选举：如果许多追随者在同一时刻都成为了候选人，**选票会被分散**，可能没有候选人能获得大多数的选票。当这种情形发生时，每一个候选人都会超时，并且通过自增任期号和发起另一轮 RequestVote RPC 来开始新的选举。然而，如果没有其它手段来分配选票的话，这种情形可能会无限的重复下去。**为了防止在一开始是选票就被瓜分，选举超时时间是在一个固定的间隔内随机选出来的（例如，150~300ms）。**

### 5.3 日志复制

一旦选出来领导人，它就开始接受 client 的请求。每个 client 请求都包含一条需要被复制状态机执行的命令。leader 把这条命令作为新的日志加入到它的日志中去，然后并行的向其他服务器发起**AppendEntries RPC**，要求其他服务器复制这个条目。当这个条目被安全的复制之后（具体怎么安全复制接下会详解），leader 会将这个条目应用到它的状态机中并会向客户返回执行结果。如果 follower 崩溃了或者运行缓慢，网络丢包，leader 会无限重试**AppendEntries RPC**直到所有的 follower 最终存储了所有的日志条目。

![](http://wx1.sinaimg.cn/mw690/4858d6a8ly1fc9zgzzchkj20hl0d7wg4.jpg)

日志就像上图一样，每个日志条目存储着一条被**状态机执行的命令**和**当这条日志条目被 leader 接受的任期号**.日志条目中的**任期号用来检测在不同服务器上日志的不一致性**,并且能确保一些特性。每个日志条目也包含一个整数索引来表示它在日志中的位置。

领导人决定什么时候将日志条目应用到状态机是安全的；这种条目被称为可被提交（commited）。Raft 保证可被提交（commited）的日志条目是持久化的并且最终会被所有可用的状态机执行。一旦被领导人创建的条目已经复制到了大多数的服务器上，这个条目就称为可被提交的（例如，图-6中的7号条目）。领导人日志中之前的条目都是可被提交的（commited），包括由之前的领导人创建的条目。5.4节将会讨论当领导人更替之后这条规则的应用问题的细节，并且也讨论了这种提交方式是安全的。领导人跟踪记录它所知道的被提交条目的最大索引值，并且这个索引值会包含在之后的 AppendEntries RPC 中（包括心跳 heartbeat 中），为的是让其他服务器都知道这条条目已经提交。一旦一个追随者知道了一个日志条目已经被提交，它会将该条目应用至本地的状态机（按照日志顺序）。

我们设计了 Raft 日志机制来保证不同服务器上日志的一致性。这样做不仅简化了系统的行为使得它更可预测，并且也是保证安全性不可或缺的一部分。Raft 保证以下特性，并且也保证了 表-3 中的日志匹配原则（Log Matching Property）:
- 如果在不同的日志中的二个条目有着**相同**的索引和任期号，则它们存储的命令是相同的。
- 如果在不同日志中的二个条目有着相同的索引和任期号，则它们之间的所有条目都是完全一样的。

第一条特性来自于：leader 在一个任期里在给定的一个日志索引位置**最多创建一条日志目录，同时该条目在日志中的位置也不会发生改变**

第二个特性源于AppendEntries RPC的一个简单的一致性检查。当发送一个AppendEntries RPC时，leader 会把新日志条目紧接着**之前**的条目的索引位置和任期号都包含在里面。如果 follower 没有在他的日志中找到相同索引和任期号的日志，它就会拒绝新的日志条目。这个一致性检查就像一个归纳步骤：**一开始空的日志的状态一定是满足日志匹配原则的，一致性检查保证了当日志添加时的日志匹配原则。**因此，只要 AppendEntries 返回成功的时候，领导人就知道追随者们的日志和它的是一致的了。

![](http://wx2.sinaimg.cn/mw690/4858d6a8ly1fca1aw93cnj20gf0baabf.jpg)
图：当最上边的领导人掌权之后，追随者日志可能有以下情况（a~f）。一个格子表示一个日志条目；格子中的数字是它的任期。一个追随者可能会丢失一些条目（a, b）；可能多出来一些未提交的条目（c, d）；或者两种情况都有（e, f）。例如，场景 f 在如下情况下就会发生：如果一台服务器在任期2时是领导人并且往它的日志中添加了一些条目，然后在将它们提交之前就宕机了，之后它很快重启了，成为了任期3的领导人，又往它的日志中添加了一些条目，然后在任期2和任期3中的条目提交之前它又宕机了并且几个任期内都一直处于宕机状态。

在一般情况下，领导人和追随者们的日志保持一致，因此 AppendEntries 一致性检查通常不会失败。然而，领导人的崩溃会导致日志不一致（旧的领导人可能没有完全复制完日志中的所有条目）。这些不一致会导致一系列领导人和追随者崩溃。图 阐述了一些追随者可能和新的领导人日志不同的情况。一个追随者可能会丢失掉领导人上的一些条目，也有可能包含一些领导人没有的条目，也有可能两者都会发生。丢失的或者多出来的条目可能会持续多个任期。

在 Raft 算法中，领导人通过强制追随者们复制它的日志来处理日志的不一致。这就意味着，在追随者上的冲突日志会被领导者的日志覆盖。5.4节会说明当添加了一个额外的限制之后这是安全的。

**leader 如何确保 follower 日志的一致性？**
为了使得追随者的日志同自己的一致，leader需要找到follower 同它的日志一致的地方，然后删除 follower 在该位置之后的日志条目，接着将自己在该位置之后的日志条目发送给追随者。这些操作都是在 AppendEntries RPC 进行一致性监察时完成的。Leader 给每一个 follower 维护了一个**nextIndex**,它表示 follower 将要发送给该 follower 的下一个日志条目的索引。

当 leader 开始掌权时，它会将**nextIndex**初始化为它的最新日志条目索引数+1（如下图中的11）。如果一个 follower 的日志和 leader 的不一致， AppendEntries RPC一致性检查会在一下次AppendEntries RPC 时返回失败。在失败之后，leader 会将nextIndex递减然后重试 AppendEntries RPC。最终nextIndex会达到一个 leader 和 follower 一致的地方。这时 AppendEntries RPC会返回成功，follower 中冲突的日志条目都会被移除了，并且添加所有缺少的 leader 发送来的日志条目。**一旦 AppendEntries 返回成功，leader 和 follower 的日志就一致了，这样的状态会保持到该任期结束。**

通过这种机制，一个领导人在掌权时不需要采取另外特殊的方式来恢复日志的一致性。它只需要使用一些常规的操作，通过响应 AppendEntries 一致性检查的失败能使得日志自动的趋于一致。一个领导人从来不会覆盖或者删除自己的日志（表-3 中的领导人只增加原则）。

这个日志复制机制展示了在第2章中阐述的所希望的一致性特性：raft 能够接受，复制并且应用新的日志条目，只要大部分的服务器是正常的，在通常情况下，一个新的日志条目可以在一轮RPC内完成在集群的大多数服务器上的复制;并且这个速度很慢的服务器不会影响整体的性能.

### 5.4安全性

之前的章节中讨论了 Raft 算法是如何进行领导选取和复制日志的。然而，到目前为止这个机制还不能保证每一个状态机能按照相同的顺序执行同样的指令。

例如：当 leader 向 follower提交了若干日志条目，同时 follower 可能宕机了，之后这个 follower被选为 leader 然后用新的日志条目覆盖掉了旧的那些，最后，不同的状态机可能执行不同的命令序列。

这一节通过在领带人选取部分加入了一个限制来完善了 Raft 算法。**这个限制能够保证对于固定的任期，任何的领导人都拥有之前任期提交的全部日志条目。**

####5.4.1 选举限制
在所有的以领导人为基础的一致性算法中，领导人最终必须要存储全部已经提交的日志条目。在一些一致性算法中，例如：Viewstamped Replication，即使一开始没有包含全部已提交的条目也可以被选为领导人。这些算法都有一些另外的机制来保证找到丢失的条目并将它们传输给新的领导人，这个过程要么在选举过程中完成，要么在选举之后立即开始。不幸的是，这种方式大大增加了复杂性。Raft 使用了一种更简单的方式来保证在新的领导人开始选举的时候在之前任期的所有已提交的日志条目都会出现在上边，而不需要将这些条目传送给领导人。**这就意味着日志条目只有一个流向：从领导人流向追随者。领导人永远不会覆盖已经存在的日志条目**

Raft 使用投票的方式阻止没有包含全部日志条目的服务器赢得选举. 一个候选人为了赢得选举必须要和集群中的大多数进行通信,这就意味着每一条已经提交的日志条目至少在其中的一台服务器上出现过。如果候选人的日志至少和大多数服务器上的日志一样新(up-to-date)，那么它一定会包含有全部的以及提交的日志条目。**RequestVote RPC 实现了这个限制：这个 RPC（远程过程调用）包括候选人的日志信息，如果它自己的日志比候选人的日志要新，那么它会拒绝候选人的投票请求。**

Raft 通过比较日志中最后一个条目的索引和任期号来决定两个日志哪一个更新。如果两个日志的任期号不同，任期号大的更新；如果任期号相同，更长的日志更新(more up-to-date)。
#### 5.4.2 提交之前任期的日志条目
![](http://wx4.sinaimg.cn/mw690/4858d6a8ly1fcc521xcvnj20ih08o75m.jpg)

只要日志条目被存储在大多数服务器上，领导人就知道当期任期就可以提交该条目了。如果领导人在提交之前就崩溃了，之后的领导人会继续完成对日志的复制。然而，领导人并不能断定存储在大多数服务器上的日志条目一定在之前的任期中被提交。图-8 说明了一种情况，一条存储在了大多数服务器上的日志条目仍然被新上任的领导人覆盖了。

为了消除上述问题，Raft 从来**不会通过计算复制数目来提交之前任期的日志条目，只有leader 当前任期的日志条目才能通过计算数目来进行提交。**一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配原则，之前的日志条目也都会被间接的提交。在某些情况下，领导人可以安全的知道一个老的日志条目是否已经被提交（例如，通过观察该条目是否存储到所有服务器上），但是 Raft 为了简化问题使用了一种更加保守的方法。

因为当领导人从之前任期复制日志条目时，日志条目保留了它们最开始的任期号，所以这使得 raft 在提交规则中增加了额外的复杂性。在其他的一致性算法中，如果一个新的 leader 要从之前的任期鸿复制日志条目，它**必须要使用当前的新任期号** 。Raft 的方法使得判断日志更加容易，因为它们全称都保持着相同的任期号。另外，和其它的一致性算法相比，Raft 算法中的新 leader 会发送更少的之前任期的日志条目（其他算法必须要发送冗余的日志条目并且在它们被提交之前来重新排序）。  


#### 5.4.3 安全论证

状态机安全原则（State Machine Safety）讲的是如果一台服务器将给定索引上的日志条目应用到了它自己的状态机上，其它服务器的同一索引位置不可能应用的是其它条目。在一个服务器应用一条日志条目到它自己的状态机中时，它的日志必须和领导人的日志在该条目和之前的条目上相同，并且已经被提交

最后，Raft 算法需要服务器按照日志中索引位置顺序应用日志条目。和状态机安全特性结合起来看，这就意味着所有的服务器会应用相同的日志序列集到自己的状态机中，并且是按照相同的顺序。

### 5.5 follower 和 candidate 崩溃
截止到目前，我们只讨论了领导人崩溃的问题。追随者和候选人崩溃的问题解决起来要比领导人崩溃要简单得多，这两者崩溃的处理方式是一样的。**如果一个追随者或者候选人崩溃了，那么之后的发送给它的 RequestVote RPC 和 AppendEntries RPC 会失败。Raft 通过无限的重试来处理这些失败**；如果崩溃的服务器重启了，RPC 就会成功完成。如果一个服务器在收到了 RPC 之后但是在响应之前崩溃了，那么它会在重启之后再次收到同一个 RPC。因为 Raft 中的 RPC 都是幂等的，因此不会有什么问题。例如，如果一个追随者收到了一个已经包含在它的日志中的 AppendEntries 请求，它会忽视这个新的请求。
### 5.6 时序和可用性
我们对于 Raft 的要求之一就是安全性不依赖于时序（timing）：系统不能仅仅因为一些事件发生的比预想的快一些或慢一些就产生错误。然而，可用性（系统可以及时响应客户端的特性）不可避免的要依赖时序。例如，如果消息交换在服务器崩溃时花费更多的时间，候选人不会等待太长的时间来赢得选举；没有一个稳定的领导人，Raft 将无法工作。

领导人选取是 Raft 中对时序要求最关键的地方。Raft 会选出并且保持一个稳定的领导人只有系统满足下列时序要求（timing requirement）：

broadcastTime << electionTimeout << MTBF

在这个不等式中，`broadcastTime`指的是一台服务器并行的向集群中的其他服务器发送 RPC 并且收到它们的响应的平均时间；`electionTimeout`指的就是在 5.2节 描述的选举超时时间；MTBF指的是单个服务器发生故障的间隔时间的平均数。

`broadcastTime`应该比`electionTimeout`小一个数量级，为的是使领导人能够持续发送心跳信息（heartbeat）来阻止追随者们开始选举；根据已经给出的随机化选举超时时间方法，这个不等式也使得瓜分选票的情况变成不可能。`electionTimeout`也要比MTBF小几个数量级，为的是使得系统稳定运行。当领导人崩溃时，整个大约会在`electionTimeout`的时间内不可用；我们希望这种情况仅占全部时间的很小的一部分。

broadcastTime和MTBF是由系统决定的性质，但是electionTimeout是我们必须做出选择的。Raft 的 RPC 需要接收方将信息持久化的保存到稳定存储中去，所以广播时间大约是 0.5 毫秒到 20 毫秒，这取决于存储的技术。因此，electionTimeout一般在 10ms 到 500ms 之间。大多数的服务器的MTBF都在几个月甚至更长，很容易满足这个时序需求。

##6 集群成员变化