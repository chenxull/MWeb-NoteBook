# StatefulSet 2
statefulset 的存储状态. StatefulSet 对存储状态的管理机制。这个机制，主要使用的是一个叫作 Persistent Volume Claim 的功能。

用户在挂载存储的时候,并不知道有哪些 Volume 类型可以用,**Kubernetes 项目引入了一组叫作 Persistent Volume Claim（PVC）和 Persistent Volume（PV）的 API 对象，大大降低了用户声明和使用持久化 Volume 的门槛。**

有了 PVC 之后,开发人员想要使用一个 Volume 只需要简单的二步即可. 

-  **第一步:**定义一个 PVC ,声明想要的 Volume 的属性

```
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: pv-claim
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi

```
可以看到在 PVC 对象中,不需要任何关于 Volume 细节的字段,只有描述的属性和定义.

- **第二步:**在应用的 Pod 中，声明使用这个 PVC 

```
apiVersion: v1
kind: Pod
metadata:
  name: pv-pod
spec:
  containers:
    - name: pv-container
      image: nginx
      ports:
        - containerPort: 80
          name: "http-server"
      volumeMounts:
        - mountPath: "/usr/share/nginx/html"
          name: pv-storage
  volumes:
    - name: pv-storage
      persistentVolumeClaim:
        claimName: pv-claim

```
可以看到，在这个 Pod 的 Volumes 定义中，我们只需要声明它的类型是 persistentVolumeClaim，然后指定 PVC 的名字，而完全不必关心 Volume 本身的定义。

这时候，只要我们创建这个 PVC 对象，Kubernetes 就会自动为它绑定一个符合条件的 Volume。可是，这些符合条件的 Volume 又是从哪里来的呢？

来自于**由运维人员维护的 PV 对象**,这是一段 PV 对象的 YAML 文件。


```
kind: PersistentVolume
apiVersion: v1
metadata:
  name: pv-volume
  labels:
    type: local
spec:
  capacity:
    storage: 10Gi
  rbd:
    monitors:
    - '10.16.154.78:6789'
    - '10.16.154.82:6789'
    - '10.16.154.83:6789'
    pool: kube
    image: foo
    fsType: ext4
    readOnly: true
    user: admin
    keyring: /etc/ceph/keyring
    imageformat: "2"
    imagefeatures: "layering"

```

可以看到，这个 PV 对象的 spec.rbd 字段，正是我们前面介绍过的 Ceph RBD Volume 的详细定义。而且，它还声明了这个 PV 的容量是 10 GiB。这样，Kubernetes 就会为我们刚刚创建的 PVC 对象绑定这个 PV。

kubernetes 中的 PVC 和 PV 的设计,**实际上类似于 接口 和实现的思想**.开发者只要知道并会使用接口 即(PVC),而运维人员负责给`接口`绑定具体的实现,即 PV.

这种解耦，就避免了因为向开发者暴露过多的存储系统细节而带来的隐患。此外，这种职责的分离，往往也意味着出现事故时可以更容易定位问题和明确责任，从而避免“扯皮”现象的出现。

在 pod 模板中声明了需要使用的挂载盘的先关信息（pvc），这个自动创搭建的 pvc 与 pv 绑定成功后，就会进入 Bound 状态,这意味着这个pod 可以挂载并使用这个 pv 了.

### 如何确保重新创建的 pod 使用相同的 pv

可以从 statefulset 控制器回复这个 pod 的过程理解。 首先，当你删除一个 pod 时，这个 pod 对应的 PVC 和 PV 并不会被删除,而这个 Volume 里已经写入了数据,也依然会保存在远程存储服务里.

这是,statefulset 控制器发现,一个叫 web-0 的 pod 消失了,所以，控制器就会重新创建一个新的、名字还是叫作 web-0 的 Pod 来，“纠正”这个不一致的情况。

需要注意的是，在这个新的 Pod 对象的定义里，它声明使用的 PVC 的名字，还是叫作：www-web-0。这个 PVC 的定义，还是来自于 PVC 模板（volumeClaimTemplates），这是 StatefulSet 创建 Pod 的标准流程。

所以，在这个新的 web-0 Pod 被创建出来之后，Kubernetes 为它查找名叫 www-web-0 的 PVC 时，就会直接找到旧 Pod 遗留下来的同名的 PVC，进而找到跟这个 PVC 绑定在一起的 PV。

**通过上述一系列流程,kubernetes 的 statefulset 就实现了对应存储状态的管理.**

### 创建流程

1. **statefulSet 的控制器直接管理 Pod**,每个 pod 的命名都按照一定的规律来.
2. **kubernetes 通过 headless Service,为这些有编号的 pod,在 DNS 服务器中生成带有相同编号的 DNS 记录.**只要 StatefulSet 能够保证这些 Pod 名字里的编号不变，那么 Service 里类似于 web-0.nginx.default.svc.cluster.local 这样的 DNS 记录也就不会变，而这条记录解析出来的 Pod 的 IP 地址，则会随着后端 Pod 的删除和再创建而自动更新。这当然是 Service 机制本身的能力，不需要 StatefulSet 操心。
3. **StatefulSet 还为每一个 pod 分配并创建一个相同编号对策 pvc**.这样，Kubernetes 就可以通过 Persistent Volume 机制为这个 PVC 绑定上对应的 PV，从而保证了每一个 Pod 都拥有一个独立的 Volume。


通过上述操作,即使 pod 被删除了.但是 pvc 和 pv 保留下来,当这个 pod 被重新创建时,kubernetes 会为它找相同编号的 pvc,挂载这个 pvc 对应的 volume,从而获取到数据.

## 小结

通过梳理 statefulSet,可以看到其就是一种特殊的 Deployment,其特殊之处在于,**它的每个 pod 都被编号了.** 而且,这个编号会体现在 pod 的名字和 hostname 等标识信息上,这不仅代表了 pod 的创建顺序,也是 pod 的重要网络表示.

有了这个编号后，StatefulSet 就使用 Kubernetes 里的两个标准功能：**Headless Service** 和 **PV/PVC**，实现了对 Pod 的拓扑状态和存储状态的维护。