# 周期性任务调度器的实现

这个调度器专门用来处理 periodic 类型的 job，此 job 需要周期性调度执行。 


它的实现整体上来看分为三个部分：
- 基础调度模块
- 队列模块
- job 数据同步存储模块

## 基础调度模块

这里定义了调度器的结构体，结构如下：

```go
type basicScheduler struct {
	context   context.Context
	pool      *redis.Pool
	namespace string
	enqueuer  *enqueuer
	client    *work.Client
	ctl       lcm.Controller
}
```

具体来说这个调度器包含了：
- 后端的 redis 工作池
- 任务在 redis 中保存的 namespace
- **任务队列**：所有此类型的 job 都会被放入到这个队列中
- 访问 worker 的客户端
- job 生命周期管理器

启动调度模块，主要做了三件事：
1. 第一次启动时，获取 redis  `namespace:scheduled` 命名空间下的 job，将这些 job 从队列中删除。
2. 启动 工作队列，这个工作队列主要负责二件事
    1. 从 redis 有序集中获取 job 的` Policy` 也就是执行一个 job 所需要的所用数据信息，将这些信息存储到 本地内存中。
    2. 创建一个协程，来启动队列循环 ，来检查是否有符合条件的 job 加入队列
3. 启动 policyStore 服务，这个的实现利用了 `redis `的 sub/pub 机制。其会订阅 redis 中 `namespace:notifications`频道，这个频道中会存放 **最新的 job 信息**，当有新的 job 发布到 从频道时，存储服务会在第一时间获取到 此 job 的数据，并同步到本地的**内存中存储**（这个存储结构是一个sync.map）。

总的来说，调度模块协调整个 周期性任务的调度工作。

### 调度实现

具体调度主要做了二件事情:
1. 将传来的 job 数据，放入到工作队列中。
2. 将 job 信息 publish到 redis 中的通道中，这个频道会被 policyStore 服务监听，会在第一时间将这个数据同步到本地的内存中。

这里详细介绍一下在把传来的 job 数据放入到 redis 的过程中，需要对那些数据进行处理。
 
首先会解析出 job 中`CronSpec`字段的信息，这是 Linux 中周期性任务调度的表达式，从中可以获取到 job 下一次的执行时间，存储在 `schedule` 变量中。 将传来 Job 的Parameters 信息 clone 到一个新的 wJobParams 中，这相当于对 job 参数的一个包装，将其转为worker 能够识别的 job 参数。

然后根据上述 获取的` schedule`时间，等到时间的到来 来执行job。这里对于一个 job做了如下的封装：

```go
j := &work.Job{
				Name: p.JobName,
				ID:   p.ID, // Use the ID of policy to avoid scheduling duplicated periodic job executions.

				// This is technically wrong, but this lets the bytes be identical for the same periodic job instance.
				// If we don't do this, we'd need to use a different approach -- probably giving each periodic job its own
				// history of the past 100 periodic jobs, and only scheduling a job if it's not in the history.
				EnqueuedAt: epoch,
				// Pass parameters to scheduled job here
				Args: wJobParams,
			}
```

接下来，会将 job 这一次的执行开始的时间存储到一个名为` execution `的变量中，这其实就是` job stats`数据。

**重点来了，然后使用这个 execution 数据，给这个 job 创建生命周期的 tracker。这个 job 状态跟踪器在整个 jobservice 中，有着最重要的作用，所有 job 的执行都需要根据状态的信息来进行调整，具体之后会详细介绍。**

之后，这个 job 的将要执行时间，job 的元数据 都会通过 redis 的 ` ZADD` 指令，添加到sorted set 中。此时一次 周期性任务的调度就完成了，剩下要做的就是等待工作池中的 worker 节点获取此任务来执行。

## 队列模块

队列结构体如下：

```go

type enqueuer struct {
	namespace   string
	context     context.Context
	pool        *redis.Pool
	policyStore *policyStore
	ctl         lcm.Controller
	// Diff with other nodes
	nodeID string
	// Track the error of enqueuing
	lastEnqueueErr error
	// For stop
	stopChan chan bo
```

整个任务队列 会以**协程**的形式不停的提供服务。**主要使用来检测周期性任务是到达执行时间**，如果满足执行时间，会将重新入队，进行执行操作。

那么这个是如何判断一个 job 是否需要入队呢？

通过向 redis 的` namespace:last_periodic_enqueue`空间发送GET指令，来获取队列信息。根据 job 的执行时间，来决定是否要将 job 重新放入任务队列。

