# Job and cronjob

但是，有一类作业显然不满足这样的条件，这就是“离线业务”，或者叫作 Batch Job（计算业务）。这种业务在计算完成后就直接退出了，而此时如果你依然用 Deployment 来管理这种业务的话，就会发现 Pod 会在计算结束后退出，然后被 Deployment Controller 不断地重启；而像“滚动更新”这样的编排功能，更无从谈起了。

离线任务运行完一次之后，就会停止。如果任务运行失败了要怎么办？

比如，我们在这个例子中定义了 restartPolicy=Never，那么离线作业失败后 Job Controller 就会不断地尝试创建一个新 Pod

需要注意的是，Job Controller 重新创建 Pod 的间隔是呈指数增加的，即下一次重新创建 Pod 的动作会分别发生在 10 s、20 s、40 s …后。**而如果你定义的 restartPolicy=OnFailure，那么离线作业失败后，Job Controller 就不会去尝试创建新的 Pod。但是，它会不断地尝试重启 Pod 里的容器。**

如果一个 pod 因为某种原因，一直都无法结束呢？

在 job 的 api 对象里，有一个spec.activeDeadlineSeconds 字段可以设置最长运行时间，比如：

```
spec:
 backoffLimit: 5
 activeDeadlineSeconds: 100

```
一旦运行超过了 100 s，这个 Job 的所有 Pod 都会被终止。并且，你可以在 Pod 的状态里看到终止的原因是 reason: DeadlineExceeded。

以上，就是一个 Job API 对象最主要的概念和用法了。不过，离线业务之所以被称为 Batch Job，**当然是因为它们可以以“Batch”，也就是并行的方式去运行。**

### job Controller 对并行作业的控制方法

在 Job 对象中，负责**并行控制**的参数有二个：
1. spec.parallelism: 定义的是一个 job 在任意时间最多可以启动多少个 pod 同时运行
2. spec.completions： 定义的是 JOB 至少要完成的 pod 的数目，即 pod 的最小完成数。

**上述二个参数分别定义了作业执行的并行度，以及总共需要完成的任务数**
### 工作原理
job controller 控制的对象，直接就是 pod。

Job Controller 在控制循环中进行的调谐（Reconcile）操作，是根据实际在 Running 状态 Pod 的数目、已经成功退出的 Pod 的数目，以及 parallelism、completions 参数的值共同计算出在这个周期里，应该创建或者删除的 Pod 数目，然后调用 Kubernetes API 来执行这个操作。

## 常见的 Job 对象用法
### 简单粗暴的方法： 外部管理器+Job 模板
这种模式的特定用法是：把 Job 的 YAML 文件定义为一个“模板”，然后用一个外部工具控制这些“模板”来生成 Job。

### 第二种用法：拥有固定任务数目的并行 Job。


主要用来针对 任务总数固定的场景。

### 第三种用法，也是很常用的一个用法：指定并行度（parallelism），但不设置固定的 completions 的值。

此时，你就必须自己想办法，来决定什么时候启动新 Pod，什么时候 Job 才算执行完成。在这种情况下，任务的总数是未知的，**所以你不仅需要一个工作队列来负责任务分发，还需要能够判断工作队列已经为空（即：所有的工作已经结束了）**

控制起来比较复杂，后面会引入 operator + job 对象的方式来解决这些问题。

### CronJob

**没错，CronJob 与 Job 的关系，正如同 Deployment 与 Pod 的关系一样**。CronJob 是一个专门用来管理 Job 对象的控制器。只不过，它创建和删除 Job 的依据，是 schedule 字段定义的、一个标准的Unix Cron格式的表达式。