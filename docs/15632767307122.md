# worker 如何获取 job 来执行

启动worker 的逻辑会使用协程创建二个业务逻辑：
1. 正常的 worker 运行，用来从工作队列中获取任务
2. worker 的观察者


```go
func (w *worker) start() {
	go w.loop()
	go w.observer.start()
}
```
## work loop 逻辑

整体实现，通过使用 for循环，里面设置一个定时器。当定时器触发时，就会触发工作处理逻辑。

处理逻辑大致如下：
1. worker 获取一个工作
2. 成功获取工作后，调动 worker 的处理进程

那么 worker 是如何获取到一个 job 的呢？

是通过 lua 脚本，发送到 redis 服务器上，从中获取到 job 的信息。接下来就是处理这个 job。

需要将一下几个 参数传入到` lua`脚本中
```
		scriptArgs = append(scriptArgs, s.redisJobs, s.redisJobsInProg, s.redisJobsPaused, s.redisJobsLock, s.redisJobsLockInfo, s.redisJobsMaxConcurrency) // KEYS[1-6 * N]

```
### lub 脚本 获取 job
这个 lua 脚本的具体定义如下：


```lua

// Used to fetch the next job to run
//
// KEYS[1] = the 1st job queue we want to try, eg, "work:jobs:emails"
// KEYS[2] = the 1st job queue's in prog queue, eg, "work:jobs:emails:97c84119d13cb54119a38743:inprogress"
// KEYS[3] = the 2nd job queue...
// KEYS[4] = the 2nd job queue's in prog queue...
// ...
// KEYS[N] = the last job queue...
// KEYS[N+1] = the last job queue's in prog queue...
// ARGV[1] = job queue's workerPoolID
var redisLuaFetchJob = fmt.Sprintf(`
local function acquireLock(lockKey, lockInfoKey, workerPoolID)
  redis.call('incr', lockKey)
  redis.call('hincrby', lockInfoKey, workerPoolID, 1)
end

local function haveJobs(jobQueue)
  return redis.call('llen', jobQueue) > 0
end

local function isPaused(pauseKey)
  return redis.call('get', pauseKey)
end

local function canRun(lockKey, maxConcurrency)
  local activeJobs = tonumber(redis.call('get', lockKey))
  if (not maxConcurrency or maxConcurrency == 0) or (not activeJobs or activeJobs < maxConcurrency) then
    -- default case: maxConcurrency not defined or set to 0 means no cap on concurrent jobs OR
    -- maxConcurrency set, but lock does not yet exist OR
    -- maxConcurrency set, lock is set, but not yet at max concurrency
    return true
  else
    -- we are at max capacity for running jobs
    return false
  end
end

local res, jobQueue, inProgQueue, pauseKey, lockKey, maxConcurrency, workerPoolID, concurrencyKey, lockInfoKey
local keylen = #KEYS
workerPoolID = ARGV[1]

for i=1,keylen,%d do
  jobQueue = KEYS[i]
  inProgQueue = KEYS[i+1]
  pauseKey = KEYS[i+2]
  lockKey = KEYS[i+3]
  lockInfoKey = KEYS[i+4]
  concurrencyKey = KEYS[i+5]

  maxConcurrency = tonumber(redis.call('get', concurrencyKey))

  if haveJobs(jobQueue) and not isPaused(pauseKey) and canRun(lockKey, maxConcurrency) then
    acquireLock(lockKey, lockInfoKey, workerPoolID)
    res = redis.call('rpoplpush', jobQueue, inProgQueue)
    return {res, jobQueue, inProgQueue}
  end
end
return nil`, fetchKeysPerJobType)

```



---
在启动 job 之前，会启动 observer，需要使用 job 的 name，ID，args 作为参数来启动。 并将这个 observer 赋值给 job，成为 job 专属的监视器。
## observer 逻辑

observer 就是一个 channel：

```go

func (o *observer) observeStarted(jobName, jobID string, arguments map[string]interface{}) {
	o.observationsChan <- &observation{
		kind:      observationKindStarted,
		jobName:   jobName,
		jobID:     jobID,
		startedAt: nowEpochSeconds(),
		arguments: arguments,
	}
}
```

带有这个 job 的一些基本信息以及何时启动的。

## Run
这个 worker 节点运行 job 的核心，调用如下的函数： job基本信息，worker context 类型，日志中间件，以及这个 **job 的类型**

```go
		_, runErr = runJob(job, w.contextType, w.middleware, jt)

```
是如何使用上述几个参数，来执行一个任务的呢？

下面我们先来介绍一个 `jt`的构成吧，


在注册 job 的时候，已经将具体 job 的名称与其 **空结构体指针**，一起注册到 `worker pool` 中。其中注册的时候，实际上是注册的下列的函数：

```
func(job *work.Job) error {
			return redisJob.Run(job)
		}
```

这是一个对 job 的包装，redisJob 包含三个部分： job对应的就是 一个具体job的结构体空指针类似于这样`(*scan.ClairJob)(nil)` ，context 信息和生命周期管理器，用来管理一个 job 状态信息。

```
RedisJob{
		job:     job,
		context: ctx,
		ctl:     ctl,
	}
```

将这三样信息放在一起构成了 redis 能够识别的任务，将这个**redisJob.Run** 方法连同 job name 一起注册到 gocraft 框架中的` jobType`中，其中最关键的这个关于具体 job 的` Run`方法存在在 job.Type的`GenericHandler`字段。

通过上述的操作，就构建完成了 job 运行时所需要的 jt 参数。


在 gocraft 框架的 Run 逻辑中，直接调用了之前注册的 handler 函数，同时传入了 需要执行 job 的相关信息。这样这个 job 就可以正常运行了。 
```
if jt.IsGeneric {
			// 将 job 的信息，传送给job handler 函数处理
			return jt.GenericHandler(job)
		}
```

因为在注册的时候，同时注册了job 生命周期管理器，这样在 job 执行的时候，就可以通过 job ID 获取到 job 的状态信息。