# Custom Metrics

自定义监控指标，在过去的很多 PaaS 项目中，其实都有一种叫作 **Auto Scaling，即自动水平扩展的功能。**只不过，这个功能往往只能依据某种指定的资源类型执行水平扩展，比如** CPU 或者 Memory 的使用值**。

而在真实的场景中，**用户需要进行 Auto Scaling 的依据往往是自定义的监控指标。**比如，某个应用的等待队列的长度，或者某种应用相关资源的使用情况。这些复杂多变的需求，在传统 PaaS 项目和其他容器编排项目里，几乎是不可能轻松支持的。

而凭借强大的** API 扩展机制**，Custom Metrics 已经成为了 Kubernetes 的一项标准能力。并且，Kubernetes 的自动扩展器组件 **Horizontal Pod Autoscaler （HPA）， 也可以直接使用 Custom Metrics 来执行用户指定的扩展策略，这里的整个过程都是非常灵活和可定制的。**

不难想到，Kubernetes 里的 Custom Metrics 机制，也是**借助 Aggregator APIServer 扩展机制来实现的。**这里的具体原理是，当你把 Custom Metrics APIServer 启动之后，Kubernetes 里就会出现一个叫作custom.metrics.k8s.io的 API。**而当你访问这个 URL 时，Aggregator 就会把你的请求转发给 Custom Metrics APIServer 。**

而 Custom Metrics APIServer 的实现，其实就是一个 Prometheus 项目的 Adaptor。

比如，现在我们要实现一个根据指定 Pod 收到的 HTTP 请求数量来进行 Auto Scaling 的 Custom Metrics，这个 Metrics 就可以通过访问如下所示的自定义监控 URL 获取到：

```
https://<apiserver_ip>/apis/custom-metrics.metrics.k8s.io/v1beta1/namespaces/default/pods/sample-metrics-app/http_requests 

```

这里的工作原理是，当你访问这个 URL 的时候，**Custom Metrics APIServer 就会去 Prometheus 里查询名叫 sample-metrics-app 这个 Pod 的 http_requests 指标的值，然后按照固定的格式返回给访问者。**

当然，http_requests 指标的值，就需要由 Prometheus 按照我在上一篇文章中讲到的核心监控体系，从目标 Pod 上采集来。

这里具体的做法有很多种，最普遍的做法，就是让 Pod 里的应用本身**暴露出一个 /metrics API，然后在这个 API 里返回自己收到的 HTTP 的请求的数量。**所以说，接下来 HPA 只需要定时访问前面提到的自定义监控 URL，然后根据这些值计算是否要执行 Scaling 即可。

接下来，我通过一个具体的实例，来为你讲解一下 Custom Metrics 具体的使用方式。这个实例的 GitHub 库在这里，你可以点击链接查看。在这个例子中，我依然会假设你的集群是 kubeadm 部署出来的，所以 Aggregator 功能已经默认开启了。